<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>tsdst.distributions &#8212; tsdst 1.0.11 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/bootstrap-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="../../_static/js/jquery-1.11.0.min.js "></script>
<script type="text/javascript" src="../../_static/js/jquery-fix.js "></script>
<script type="text/javascript" src="../../_static/bootstrap-3.3.7/js/bootstrap.min.js "></script>
<script type="text/javascript" src="../../_static/bootstrap-sphinx.js "></script>

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../../index.html">
          tsdst</a>
        <span class="navbar-text navbar-version pull-left"><b></b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../api.html">API Pages</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"></ul>
</li>
              
            
            
              
                
              
            
            
            
            
              <li class="hidden-sm"></li>
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="body col-md-12 content" role="main">
      
  <h1>Source code for tsdst.distributions</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">norm</span> <span class="k">as</span> <span class="n">normal</span><span class="p">,</span> <span class="n">lognorm</span><span class="p">,</span> <span class="n">gamma</span>
<span class="kn">from</span> <span class="nn">scipy.special</span> <span class="kn">import</span> <span class="n">xlogy</span><span class="p">,</span> <span class="n">loggamma</span>

<span class="kn">from</span> <span class="nn">.tmath</span> <span class="kn">import</span> <span class="n">norm</span>


<span class="c1"># #########################################</span>
<span class="c1"># ########## General Functions ############</span>
<span class="c1"># #########################################</span>


<span class="c1"># This is a faster approximation of the normal quantile function.</span>
<span class="c1"># Accurate to 2 or 3 digits. For exact solutions, use dwrap or scipy</span>
<div class="viewcode-block" id="qnorm_approx"><a class="viewcode-back" href="../../generated/tsdst.distributions.qnorm_approx.html#tsdst.distributions.qnorm_approx">[docs]</a><span class="k">def</span> <span class="nf">qnorm_approx</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">lt</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;This is a faster approximation of the normal quantile function (At least</span>
<span class="sd">    this was true at the time I last benchmarked it). Accurate to 2 or 3</span>
<span class="sd">    digits. For exact solutions, use :func:`dwrap` or :any:`scipy.stats`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    p : float or array-like</span>
<span class="sd">        percentile (or probability) of interest.</span>
<span class="sd">    mu : float, optional</span>
<span class="sd">        Mean of the normal distribution. The default is 0.</span>
<span class="sd">    sigma : float, optional</span>
<span class="sd">        Standard deviation of the normal distribution. The default is 1.</span>
<span class="sd">    lt : bool, optional</span>
<span class="sd">        Lower tail of the distribution. The default is True.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    quant : float or numpy array</span>
<span class="sd">        Return quantile of interest.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from tsdst.distributions import qnorm_approx</span>
<span class="sd">    &gt;&gt;&gt; </span>
<span class="sd">    &gt;&gt;&gt; data = np.array([0.5,0.975])</span>
<span class="sd">    &gt;&gt;&gt; </span>
<span class="sd">    &gt;&gt;&gt; qnorm_approx(p=data, mu=0, sigma=1, lt=True)</span>
<span class="sd">    array([0.        , 1.95904894])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">lt</span><span class="p">:</span>
        <span class="n">p</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">p</span>
    <span class="n">a</span> <span class="o">=</span> <span class="mf">0.147</span>
    <span class="n">x</span> <span class="o">=</span> <span class="mf">2.0</span><span class="o">*</span><span class="n">p</span> <span class="o">-</span> <span class="mf">1.0</span>
    <span class="n">b</span> <span class="o">=</span> <span class="p">(</span><span class="mf">2.0</span><span class="o">/</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">a</span><span class="p">))</span> <span class="o">+</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="mf">2.0</span><span class="p">)</span>
    <span class="n">c</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="n">a</span><span class="p">)</span>
    <span class="n">i_erf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">b</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="n">c</span><span class="p">)</span> <span class="o">-</span> <span class="n">b</span><span class="p">)</span>
    <span class="n">quant</span> <span class="o">=</span> <span class="n">mu</span> <span class="o">+</span> <span class="n">sigma</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="n">i_erf</span>
    <span class="k">return</span> <span class="n">quant</span></div>


<div class="viewcode-block" id="pnorm_approx"><a class="viewcode-back" href="../../generated/tsdst.distributions.pnorm_approx.html#tsdst.distributions.pnorm_approx">[docs]</a><span class="k">def</span> <span class="nf">pnorm_approx</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">lt</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;This is a fast approximation of the normal cdf, accurate to 1.5e-7.</span>
<span class="sd">    For exact solutions, use :func:`dwrap` or :any:`scipy.stats`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    q : float</span>
<span class="sd">        Quantile of interest.</span>
<span class="sd">    mu : float, optional</span>
<span class="sd">        Mean of the normal distribution. The default is 0.</span>
<span class="sd">    sigma : float, optional</span>
<span class="sd">        Standard deviation of the normal distribution. The default is 1.</span>
<span class="sd">    lt : bool, optional</span>
<span class="sd">        Use lower tail. The default is True.</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        Return log of the value. The default is False.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    prob : float</span>
<span class="sd">        The probability at the given quantile.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from tsdst.distributions import pnorm_approx</span>
<span class="sd">    &gt;&gt;&gt; </span>
<span class="sd">    &gt;&gt;&gt; data = np.array([0, 1.96])</span>
<span class="sd">    &gt;&gt;&gt; params = np.array([0, 1])</span>
<span class="sd">    &gt;&gt;&gt; </span>
<span class="sd">    &gt;&gt;&gt; pnorm_approx(q=data, mu=0, sigma=1, lt=True, log=False)</span>
<span class="sd">    array([0.5       , 0.97500217])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="mf">0.3275911</span>
    <span class="n">a1</span> <span class="o">=</span> <span class="mf">0.254829592</span>
    <span class="n">a2</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.284496736</span>
    <span class="n">a3</span> <span class="o">=</span> <span class="mf">1.421413741</span>
    <span class="n">a4</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.453152027</span>
    <span class="n">a5</span> <span class="o">=</span> <span class="mf">1.061405429</span>
    <span class="n">x</span> <span class="o">=</span> <span class="p">(</span><span class="n">q</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">sigma</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
    <span class="n">sx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">t</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">p</span><span class="o">*</span><span class="n">ax</span><span class="p">))</span>
    <span class="n">erf</span> <span class="o">=</span> <span class="n">sx</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">a1</span><span class="o">*</span><span class="n">t</span> <span class="o">+</span>
                <span class="n">a2</span><span class="o">*</span><span class="p">(</span><span class="n">t</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span>
                <span class="n">a3</span><span class="o">*</span><span class="p">(</span><span class="n">t</span><span class="o">**</span><span class="mi">3</span><span class="p">)</span> <span class="o">+</span>
                <span class="n">a4</span><span class="o">*</span><span class="p">(</span><span class="n">t</span><span class="o">**</span><span class="mi">4</span><span class="p">)</span> <span class="o">+</span>
                <span class="n">a5</span><span class="o">*</span><span class="p">(</span><span class="n">t</span><span class="o">**</span><span class="mi">5</span><span class="p">))</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">ax</span><span class="o">**</span><span class="mi">2</span><span class="p">)))</span>

    <span class="n">prob</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">erf</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">lt</span><span class="p">:</span>
        <span class="n">prob</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">prob</span>
    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">prob</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">prob</span></div>


<div class="viewcode-block" id="dpoibin_PA"><a class="viewcode-back" href="../../generated/tsdst.distributions.dpoibin_PA.html#tsdst.distributions.dpoibin_PA">[docs]</a><span class="k">def</span> <span class="nf">dpoibin_PA</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Poisson approximation of the Poisson-Binomial probability mass function.</span>
<span class="sd">    Fast, but possibly inaccurate.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    k : numpy array or int</span>
<span class="sd">        The poisson counts.</span>
<span class="sd">    p : numpy array or float</span>
<span class="sd">        Binomial probabilities.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    prob : float</span>
<span class="sd">        The mass of the poisson-binomial distribution.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    dpoibin_exact, dpoibin_FT, ppoibin_RNA</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from tsdst.distributions import dpoibin_PA</span>
<span class="sd">    &gt;&gt;&gt; </span>
<span class="sd">    &gt;&gt;&gt; p = np.array([0.5, 0.975, 0.3])</span>
<span class="sd">    &gt;&gt;&gt; k = np.array([2, 3])</span>
<span class="sd">    &gt;&gt;&gt; </span>
<span class="sd">    &gt;&gt;&gt; dpoibin_PA(k, p)</span>
<span class="sd">    array([0.2669894 , 0.15796873])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">lmbda</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
    <span class="n">prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">k</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">lmbda</span><span class="p">)</span> <span class="o">-</span> <span class="n">lmbda</span> <span class="o">-</span> <span class="n">loggamma</span><span class="p">(</span><span class="n">k</span> <span class="o">+</span> <span class="mf">1.0</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">prob</span></div>


<div class="viewcode-block" id="ppoibin_RNA"><a class="viewcode-back" href="../../generated/tsdst.distributions.ppoibin_RNA.html#tsdst.distributions.ppoibin_RNA">[docs]</a><span class="k">def</span> <span class="nf">ppoibin_RNA</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">p_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Refined normal approximation of Poisson-Binomial Cumulative Distribution.</span>
<span class="sd">    This code is adapted from the R package &#39;poibin&#39;.</span>
<span class="sd">    Very fast for p &gt; 10000.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    k : numpy array or int</span>
<span class="sd">        Poisson counts.</span>
<span class="sd">    p : numpy array or float</span>
<span class="sd">        Binomial probabilities.</span>
<span class="sd">    p_weight : numpy array, optional</span>
<span class="sd">        Weights for the probabilities. Same length as p. The default is None.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    vkk_r : numpy array or float</span>
<span class="sd">        cumulative probabilities.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    dpoibin_exact, dpoibin_FT,</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from tsdst.distributions import ppoibin_RNA</span>
<span class="sd">    &gt;&gt;&gt; </span>
<span class="sd">    &gt;&gt;&gt; p = np.array([0.5, 0.975, 0.3])</span>
<span class="sd">    &gt;&gt;&gt; k = np.array([2, 3])</span>
<span class="sd">    &gt;&gt;&gt; </span>
<span class="sd">    &gt;&gt;&gt; ppoibin_RNA(k, p, p_weight=None)</span>
<span class="sd">    array([0.85063305, 0.99054359])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">p</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">)</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">k</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">)</span>
    <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">p</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">any</span><span class="p">(</span><span class="n">p</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
        <span class="k">raise</span><span class="p">(</span><span class="s2">&quot;Invalid Probabilities (0 &lt;= P(x) &lt;= 1)&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">p_weight</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">p_weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>

    <span class="n">pp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">p_weight</span><span class="p">)</span>
    <span class="n">muk</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">pp</span><span class="p">)</span>
    <span class="n">sigmak</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">pp</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">pp</span><span class="p">)))</span>
    <span class="n">gammak</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">pp</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">pp</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">pp</span><span class="p">))</span>
    <span class="n">kk1</span> <span class="o">=</span> <span class="p">(</span><span class="n">k</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">-</span> <span class="n">muk</span><span class="p">)</span><span class="o">/</span><span class="n">sigmak</span>
    <span class="n">vkk_r</span> <span class="o">=</span> <span class="p">(</span><span class="n">pnorm_approx</span><span class="p">(</span><span class="n">kk1</span><span class="p">)</span> <span class="o">+</span> <span class="n">gammak</span><span class="o">/</span><span class="p">(</span><span class="mi">6</span> <span class="o">*</span> <span class="n">sigmak</span><span class="o">**</span><span class="mi">3</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">kk1</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span>
             <span class="n">dwrap</span><span class="p">(</span><span class="n">kk1</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;pdf&quot;</span><span class="p">,</span> <span class="s2">&quot;normal&quot;</span><span class="p">))</span>
    <span class="n">vkk_r</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">vkk_r</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">vkk_r</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">vkk_r</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">vkk_r</span></div>


<div class="viewcode-block" id="dpoibin_FT"><a class="viewcode-back" href="../../generated/tsdst.distributions.dpoibin_FT.html#tsdst.distributions.dpoibin_FT">[docs]</a><span class="k">def</span> <span class="nf">dpoibin_FT</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The probability mass function for the poisson-binomial distribution using</span>
<span class="sd">    Fourier transforms. This function is written by the author of this package,</span>
<span class="sd">    and uses the discrete Fourier transform.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    k : numpy array or int</span>
<span class="sd">        Poisson counts.</span>
<span class="sd">    p : numpy array or float</span>
<span class="sd">        Binomial probabilities.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    karray : float or numpy array</span>
<span class="sd">        The mass of the poisson-binomial distribution.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    dpoibin_exact, dpoibin_PA, ppoibin_RNA</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from tsdst.distributions import dpoibin_FT</span>
<span class="sd">    &gt;&gt;&gt; </span>
<span class="sd">    &gt;&gt;&gt; p = np.array([0.5, 0.975, 0.3])</span>
<span class="sd">    &gt;&gt;&gt; k = np.array([2, 3])</span>
<span class="sd">    &gt;&gt;&gt; </span>
<span class="sd">    &gt;&gt;&gt; dpoibin_FT(k, p)</span>
<span class="sd">    array([0.49125, 0.14625])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
    <span class="n">nk</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
    <span class="n">inp1</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">L</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">C</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">((</span><span class="mi">2</span><span class="o">*</span><span class="mi">1</span><span class="n">j</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">karray</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">nk</span><span class="p">)</span>
    <span class="n">k_bool</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">((</span><span class="n">k</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">k</span> <span class="o">&gt;</span> <span class="n">n</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nk</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">k_bool</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
            <span class="n">karray</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">prodp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="p">(</span><span class="n">C</span><span class="o">**</span><span class="n">x</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">p</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">L</span><span class="p">])</span>
            <span class="n">c_calc</span> <span class="o">=</span> <span class="n">C</span><span class="o">**</span><span class="p">(</span><span class="o">-</span><span class="n">L</span><span class="o">*</span><span class="n">k</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="n">sumc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">c_calc</span> <span class="o">*</span> <span class="n">prodp</span><span class="p">)</span>
            <span class="n">res</span> <span class="o">=</span> <span class="n">inp1</span><span class="o">*</span><span class="n">sumc</span>
            <span class="n">karray</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">real</span>
    <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">karray</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">):</span>
        <span class="n">karray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">karray</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="n">karray</span></div>


<div class="viewcode-block" id="dpoibin_exact"><a class="viewcode-back" href="../../generated/tsdst.distributions.dpoibin_exact.html#tsdst.distributions.dpoibin_exact">[docs]</a><span class="k">def</span> <span class="nf">dpoibin_exact</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">cdf</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The exact probability mass function for the poisson-binomial distribution.</span>
<span class="sd">    </span>
<span class="sd">    This function is adapted from Mark Lodato of StackExchange, Nov 7&#39;16.</span>
<span class="sd">    It&#39;s fast, but runs slower than 1 second once len(p) &gt; 25000.</span>

<span class="sd">    Adapted to compute both the pdf and the cdf.</span>

<span class="sd">    Link: https://stats.stackexchange.com/questions/242233/efficiently-computing-poisson-binomial-sum</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    k : numpy array or int</span>
<span class="sd">        Poisson count, or number of successful trials (out of len(p) total trials)</span>
<span class="sd">    p : numpy array or float</span>
<span class="sd">        Binomial probabilities for each trial.</span>
<span class="sd">    cdf : bool, optional</span>
<span class="sd">        Compute the cdf. Default is False.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    karray : float or numpy array</span>
<span class="sd">        The mass of the poisson-binomial distribution.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    dpoibin_PA, dpoibin_FT, ppoibin_RNA</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from tsdst.distributions import dpoibin_exact</span>
<span class="sd">    &gt;&gt;&gt; </span>
<span class="sd">    &gt;&gt;&gt; p = np.array([0.5,0.975, 0.3])</span>
<span class="sd">    &gt;&gt;&gt; k = np.array([2, 3])</span>
<span class="sd">    &gt;&gt;&gt; </span>
<span class="sd">    &gt;&gt;&gt; dpoibin_exact(k, p, cdf=False)</span>
<span class="sd">    [0.49125 0.14625]</span>
<span class="sd">    &gt;&gt;&gt; dpoibin_exact(k, p, cdf=True)</span>
<span class="sd">    [0.85375 1.     ]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">k</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">p</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,)</span>
    
    <span class="n">n</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">karray</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
    <span class="n">pmf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">pmf</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">success</span> <span class="o">=</span> <span class="n">pmf</span><span class="p">[:</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">p</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">pmf</span><span class="p">[:</span><span class="n">i</span> <span class="o">+</span> <span class="mi">2</span><span class="p">]</span> <span class="o">*=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>  
        <span class="n">pmf</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="mi">2</span><span class="p">]</span> <span class="o">+=</span> <span class="n">success</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">k_elem</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">cdf</span><span class="p">:</span>
            <span class="n">karray</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">pmf</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="n">k_elem</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
            <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">k</span> <span class="o">&gt;</span> <span class="n">n</span><span class="p">):</span>
                <span class="n">karray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">k</span> <span class="o">&gt;</span> <span class="n">n</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">k_elem</span> <span class="o">&lt;=</span> <span class="n">n</span><span class="p">:</span>
                <span class="n">karray</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">pmf</span><span class="p">[</span><span class="n">k_elem</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">k</span> <span class="o">&gt;</span> <span class="n">n</span><span class="p">):</span>
                <span class="n">karray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">k</span> <span class="o">&gt;</span> <span class="n">n</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="nb">any</span><span class="p">((</span><span class="n">karray</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">k</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)):</span>
        <span class="n">karray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">((</span><span class="n">karray</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">k</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">))]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="n">karray</span></div>


<div class="viewcode-block" id="dwrap"><a class="viewcode-back" href="../../generated/tsdst.distributions.dwrap.html#tsdst.distributions.dwrap">[docs]</a><span class="k">def</span> <span class="nf">dwrap</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">disttype</span><span class="p">,</span> <span class="n">funct</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;This function is meant to be similar to the R distribution functions,</span>
<span class="sd">    such as dnorm, pnorm, qnorm, etc. It calculates variations of the </span>
<span class="sd">    cdf or pdf depending on the funct selected.</span>
<span class="sd">    </span>
<span class="sd">    I have found that writing the distributions in plain math is sometimes </span>
<span class="sd">    faster in python than using the scipy implementations, which is why</span>
<span class="sd">    this function originally existed. I wrote my own versions of the</span>
<span class="sd">    distributions, except where the distributions were complicated and it</span>
<span class="sd">    wasn&#39;t worth it at the time (and then this function uses scipy). However,</span>
<span class="sd">    as time goes on, that will probably change. Also, the :any:`scipy.stats`</span>
<span class="sd">    implementations and documentations are quite complete, so unless you&#39;re</span>
<span class="sd">    feeling adventurous, it&#39;s probably a good idea to just use :any:`scipy`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : numpy array or pandas dataframe/series</span>
<span class="sd">        Numeric values representing the data of interest, either a random</span>
<span class="sd">        variable, probability, or quantile.</span>
<span class="sd">    params : numpy array or pandas dataframe/series</span>
<span class="sd">        the parameters of the function of interest (shape, scale, etc.)</span>

<span class="sd">        - weibull: (shape, scale)</span>
<span class="sd">        - exponential: (rate,)</span>
<span class="sd">        - lnorm: (mu, sigma)</span>
<span class="sd">        - normal: (mu, sigma)</span>
<span class="sd">        - gamma: (shape, scale)</span>

<span class="sd">    disttype : str</span>
<span class="sd">        the distribution type, which currently includes</span>

<span class="sd">        - pdf (probability density function)</span>
<span class="sd">        - cdf (cumulative distribution function)</span>
<span class="sd">        - inv-cdf (inverse cumulative distribution function)</span>
<span class="sd">        - sf (survival function, 1 - cdf)</span>
<span class="sd">        - left-truncated-cdf</span>
<span class="sd">        - left-truncated-inv-cdf.</span>

<span class="sd">        (Note: not all of these options may be available for all funct values)</span>
<span class="sd">    funct : str</span>
<span class="sd">        the distribution function, which currently includes weibull, </span>
<span class="sd">        exponential, log-normal (as lnorm), normal, and gamma</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        Whether to use the log of the distribution or not. The default is</span>
<span class="sd">        False.</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        Raised when invalid distribution type or function is chosen.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    numpy array </span>
<span class="sd">        an array containing the evaluation of the distribution.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from tsdst.distributions import dwrap</span>
<span class="sd">    &gt;&gt;&gt; </span>
<span class="sd">    &gt;&gt;&gt; data = np.array([0.5,0.975])</span>
<span class="sd">    &gt;&gt;&gt; params = np.array([0, 1])</span>
<span class="sd">    &gt;&gt;&gt; </span>
<span class="sd">    &gt;&gt;&gt; dwrap(data, params, disttype=&quot;inv-cdf&quot;, funct=&quot;normal&quot;, log=False)</span>
<span class="sd">    array([0.        , 1.95996398])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">num_parms</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">params</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">params</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_parms</span><span class="p">)</span>
    <span class="k">except</span> <span class="p">(</span><span class="ne">IndexError</span><span class="p">,</span> <span class="ne">AttributeError</span><span class="p">):</span>
        <span class="n">params</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">params</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">funct</span> <span class="o">==</span> <span class="s2">&quot;weibull&quot;</span><span class="p">:</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="n">params</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="n">params</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">disttype</span> <span class="o">==</span> <span class="s2">&quot;pdf&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span> <span class="o">+</span>
                        <span class="n">xlogy</span><span class="p">(</span><span class="n">shape</span> <span class="o">-</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">data</span><span class="o">/</span><span class="n">scale</span><span class="p">)</span> <span class="o">-</span>
                        <span class="p">(</span><span class="n">data</span><span class="o">/</span><span class="n">scale</span><span class="p">)</span><span class="o">**</span><span class="n">shape</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">((</span><span class="n">shape</span><span class="o">/</span><span class="n">scale</span><span class="p">)</span><span class="o">*</span><span class="p">((</span><span class="n">data</span><span class="o">/</span><span class="n">scale</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="n">shape</span> <span class="o">-</span> <span class="mf">1.0</span><span class="p">))</span> <span class="o">*</span>
                        <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">data</span><span class="o">/</span><span class="n">scale</span><span class="p">)</span><span class="o">**</span><span class="n">shape</span><span class="p">))</span>
        <span class="k">elif</span> <span class="n">disttype</span> <span class="o">==</span> <span class="s2">&quot;cdf&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">((</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">data</span><span class="o">/</span><span class="n">scale</span><span class="p">)</span><span class="o">**</span><span class="n">shape</span><span class="p">)))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">data</span><span class="o">/</span><span class="n">scale</span><span class="p">)</span><span class="o">**</span><span class="n">shape</span><span class="p">))</span>
        <span class="k">elif</span> <span class="n">disttype</span> <span class="o">==</span> <span class="s2">&quot;sf&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
                <span class="k">return</span> <span class="o">-</span><span class="p">(</span><span class="n">data</span><span class="o">/</span><span class="n">scale</span><span class="p">)</span><span class="o">**</span><span class="n">shape</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">data</span><span class="o">/</span><span class="n">scale</span><span class="p">)</span><span class="o">**</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">disttype</span> <span class="o">==</span> <span class="s2">&quot;inv-cdf&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span> <span class="o">+</span> <span class="p">((</span><span class="mi">1</span><span class="o">/</span><span class="n">shape</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">data</span><span class="p">)))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">scale</span><span class="o">*</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">data</span><span class="p">))</span><span class="o">**</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">shape</span><span class="p">)</span>
        <span class="c1"># The left-truncted distribution is useful for evaluating the</span>
        <span class="c1"># censored items (probability of failing given it lived this long)</span>
        <span class="k">elif</span> <span class="n">disttype</span> <span class="o">==</span> <span class="s2">&quot;left-truncated-cdf&quot;</span><span class="p">:</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">params</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(((</span><span class="n">a</span><span class="o">/</span><span class="n">scale</span><span class="p">)</span><span class="o">**</span><span class="n">shape</span><span class="p">)</span> <span class="o">-</span> <span class="p">((</span><span class="n">data</span><span class="o">/</span><span class="n">scale</span><span class="p">)</span><span class="o">**</span><span class="n">shape</span><span class="p">))))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(((</span><span class="n">a</span><span class="o">/</span><span class="n">scale</span><span class="p">)</span><span class="o">**</span><span class="n">shape</span><span class="p">)</span> <span class="o">-</span> <span class="p">((</span><span class="n">data</span><span class="o">/</span><span class="n">scale</span><span class="p">)</span><span class="o">**</span><span class="n">shape</span><span class="p">)))</span>
        <span class="k">elif</span> <span class="n">disttype</span> <span class="o">==</span> <span class="s2">&quot;left-truncated-inv-cdf&quot;</span><span class="p">:</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">params</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">shape</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">((((</span><span class="n">a</span><span class="o">/</span><span class="n">scale</span><span class="p">)</span><span class="o">**</span><span class="n">shape</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">data</span><span class="p">)))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">scale</span><span class="o">*</span><span class="p">(((</span><span class="n">a</span><span class="o">/</span><span class="n">scale</span><span class="p">)</span><span class="o">**</span><span class="n">shape</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">data</span><span class="p">))</span><span class="o">**</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Not a valid distribution type&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">funct</span> <span class="o">==</span> <span class="s2">&quot;exponential&quot;</span><span class="p">:</span>
        <span class="n">rate</span> <span class="o">=</span> <span class="n">params</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">disttype</span> <span class="o">==</span> <span class="s2">&quot;pdf&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">rate</span><span class="p">)</span> <span class="o">-</span> <span class="n">rate</span><span class="o">*</span><span class="n">data</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">rate</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">rate</span><span class="o">*</span><span class="n">data</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">disttype</span> <span class="o">==</span> <span class="s2">&quot;cdf&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">rate</span><span class="o">*</span><span class="n">data</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">rate</span><span class="o">*</span><span class="n">data</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">disttype</span> <span class="o">==</span> <span class="s2">&quot;sf&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
                <span class="k">return</span> <span class="o">-</span><span class="n">rate</span><span class="o">*</span><span class="n">data</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">rate</span><span class="o">*</span><span class="n">data</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Not a valid distribution type&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">funct</span> <span class="o">==</span> <span class="s2">&quot;lnorm&quot;</span><span class="p">:</span>
        <span class="n">mu</span> <span class="o">=</span> <span class="n">params</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="n">sigma</span> <span class="o">=</span> <span class="n">params</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">disttype</span> <span class="o">==</span> <span class="s2">&quot;pdf&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">sigma</span><span class="p">)</span> <span class="o">+</span>
                          <span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">))</span> <span class="o">-</span>
                        <span class="p">(((</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">)))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">((</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="n">data</span><span class="o">*</span><span class="n">sigma</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)))</span> <span class="o">*</span>
                        <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">)))</span>
        <span class="k">elif</span> <span class="n">disttype</span> <span class="o">==</span> <span class="s2">&quot;cdf&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">lognorm</span><span class="o">.</span><span class="n">logcdf</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">),</span> <span class="n">s</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">lognorm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">),</span> <span class="n">s</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">disttype</span> <span class="o">==</span> <span class="s2">&quot;sf&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">lognorm</span><span class="o">.</span><span class="n">logsf</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">),</span> <span class="n">s</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">lognorm</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">),</span> <span class="n">s</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Not a valid distribution type&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">funct</span> <span class="o">==</span> <span class="s2">&quot;normal&quot;</span><span class="p">:</span>
        <span class="n">mu</span> <span class="o">=</span> <span class="n">params</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="n">sigma</span> <span class="o">=</span> <span class="n">params</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">disttype</span> <span class="o">==</span> <span class="s2">&quot;pdf&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">sigma</span><span class="p">)</span> <span class="o">-</span>
                        <span class="mf">0.5</span><span class="o">*</span><span class="p">((</span><span class="n">data</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span> <span class="o">/</span> <span class="n">sigma</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">((</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span><span class="o">*</span><span class="n">sigma</span><span class="p">))</span> <span class="o">*</span>
                        <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">((</span><span class="n">data</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">)))))</span>
        <span class="k">elif</span> <span class="n">disttype</span> <span class="o">==</span> <span class="s2">&quot;cdf&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">normal</span><span class="o">.</span><span class="n">logcdf</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">normal</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">disttype</span> <span class="o">==</span> <span class="s2">&quot;sf&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">normal</span><span class="o">.</span><span class="n">logsf</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">normal</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">disttype</span> <span class="o">==</span> <span class="s2">&quot;inv-cdf&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">normal</span><span class="o">.</span><span class="n">logppf</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">normal</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Not a valid distribution type&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">funct</span> <span class="o">==</span> <span class="s2">&quot;gamma&quot;</span><span class="p">:</span>
        <span class="n">param1</span> <span class="o">=</span> <span class="n">params</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="n">param2</span> <span class="o">=</span> <span class="n">params</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">disttype</span> <span class="o">==</span> <span class="s2">&quot;pdf&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">gamma</span><span class="o">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">param1</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">param2</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">gamma</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">param1</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">param2</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">disttype</span> <span class="o">==</span> <span class="s2">&quot;cdf&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">gamma</span><span class="o">.</span><span class="n">logcdf</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">param1</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">param2</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">gamma</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">param1</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">param2</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">disttype</span> <span class="o">==</span> <span class="s2">&quot;sf&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">gamma</span><span class="o">.</span><span class="n">logsf</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">param1</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">param2</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">gamma</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">param1</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">param2</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Not a valid distribution type&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Not a valid distribution&quot;</span><span class="p">)</span></div>


<span class="c1"># #########################################</span>
<span class="c1"># ######## Likelihood Functions ###########</span>
<span class="c1"># #########################################</span>


<div class="viewcode-block" id="likelihood_bernoulli"><a class="viewcode-back" href="../../generated/tsdst.distributions.likelihood_bernoulli.html#tsdst.distributions.likelihood_bernoulli">[docs]</a><span class="k">def</span> <span class="nf">likelihood_bernoulli</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">prob</span><span class="p">,</span> <span class="n">neg</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The likelihood for a binary output or bernoulli model.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    obs : numpy array (numeric)</span>
<span class="sd">        The true/observed bernoulli trials (the binary observations).</span>
<span class="sd">    prob : numpy array or pandas dataframe</span>
<span class="sd">        The probabilities (either one per obs, or a single value).</span>
<span class="sd">    neg : bool, optional</span>
<span class="sd">        Return negative likelihood. The default is True.</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        Return log-likelihood. The default is True.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        The likelihood.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="c1">### Alternate formulation (placing here for my notes)</span>
    <span class="c1"># loglike = obs*prob - np.log(1 + np.exp(prob))</span>
    <span class="n">loglike</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">xlogy</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">prob</span><span class="p">)</span> <span class="o">+</span> <span class="n">xlogy</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">obs</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">prob</span><span class="p">))</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">loglike</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">loglike</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">neg</span><span class="p">:</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">loglike</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">loglike</span></div>


<div class="viewcode-block" id="glm_likelihood_bernoulli"><a class="viewcode-back" href="../../generated/tsdst.distributions.glm_likelihood_bernoulli.html#tsdst.distributions.glm_likelihood_bernoulli">[docs]</a><span class="k">def</span> <span class="nf">glm_likelihood_bernoulli</span><span class="p">(</span><span class="n">parms</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">lamb</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">l_p</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">neg</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The likelihood for a logistic regression or bernoulli model with a penalty</span>
<span class="sd">    term (can accept any norm, default is 1 for L1).</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    parms : numpy array (numeric)</span>
<span class="sd">        The coefficients (including intercept, which is first)</span>
<span class="sd">    X : numpy array (numeric)</span>
<span class="sd">        The independent variables (or feature matrix), where the first column</span>
<span class="sd">        is a dummy column of 1&#39;s (for the intercept).</span>
<span class="sd">    Y : numpy array or pandas dataframe</span>
<span class="sd">        The response value (should be 0 or 1, but could be float as well if </span>
<span class="sd">        you&#39;re willing to deal with those consequences).</span>
<span class="sd">    lamb : int, optional</span>
<span class="sd">        The size of the penalty (lambda). Note this is the inverse of the</span>
<span class="sd">        common sklearn parameter C (i.e. C=1/lambda. The default is 1.</span>
<span class="sd">    l_p : int, optional</span>
<span class="sd">        The mathematical norm to be applied to the coefficients.</span>
<span class="sd">        The default is 1, representing an L1 penalty.</span>
<span class="sd">    neg : bool, optional</span>
<span class="sd">        Return negative likelihood. The default is True.</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        Return log-likelihood. The default is True.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        The likelihood.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from tsdst.distributions import glm_likelihood_bernoulli</span>
<span class="sd">    &gt;&gt;&gt; </span>
<span class="sd">    &gt;&gt;&gt; intercept = np.array([3])</span>
<span class="sd">    &gt;&gt;&gt; betas = np.array([2,4,5])</span>
<span class="sd">    &gt;&gt;&gt; params = np.concatenate((intercept, betas))</span>
<span class="sd">    &gt;&gt;&gt; </span>
<span class="sd">    &gt;&gt;&gt; np.random.seed(123)</span>
<span class="sd">    &gt;&gt;&gt; X = np.random.normal(size=(100, 3))</span>
<span class="sd">    &gt;&gt;&gt; X = np.hstack((np.repeat(1, 100).reshape(-1, 1), X))</span>
<span class="sd">    &gt;&gt;&gt; Y = np.round(np.random.uniform(low=0, high=1, size=100))</span>
<span class="sd">    &gt;&gt;&gt; </span>
<span class="sd">    &gt;&gt;&gt; glm_likelihood_bernoulli(params, X, Y, lamb=1, l_p=1)</span>
<span class="sd">    386.6152600787893</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1">#intercept = parms[0]</span>
    <span class="n">betas</span> <span class="o">=</span> <span class="n">parms</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
    
    <span class="n">mu</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">parms</span><span class="p">)</span>
    <span class="n">Ypred</span> <span class="o">=</span> <span class="mf">1.0</span><span class="o">/</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">mu</span><span class="p">))</span>
    <span class="c1">### Alternate formulation (placing here for my notes)</span>
    <span class="c1"># loglike = Y*mu - np.log(1 + np.exp(mu))</span>
    <span class="n">loglike</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">xlogy</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">Ypred</span><span class="p">)</span> <span class="o">+</span> <span class="n">xlogy</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">Y</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">Ypred</span><span class="p">))</span> <span class="o">-</span> <span class="n">lamb</span><span class="o">*</span><span class="n">norm</span><span class="p">(</span><span class="n">betas</span><span class="p">,</span> <span class="n">l_p</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">loglike</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">loglike</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">neg</span><span class="p">:</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">loglike</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">loglike</span></div>


<div class="viewcode-block" id="likelihood_poisson"><a class="viewcode-back" href="../../generated/tsdst.distributions.likelihood_poisson.html#tsdst.distributions.likelihood_poisson">[docs]</a><span class="k">def</span> <span class="nf">likelihood_poisson</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="n">neg</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The likelihood for a count output or poisson model.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : numpy array (numeric)</span>
<span class="sd">        The true count values (the poisson observations).</span>
<span class="sd">    y_score : numpy array or pandas dataframe</span>
<span class="sd">        The estimated value/values (lambda).</span>
<span class="sd">    neg : bool, optional</span>
<span class="sd">        Return negative likelihood. The default is True.</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        Return log-likelihood. The default is True.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        The likelihood.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">loglike</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y_true</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y_score</span><span class="p">)</span> <span class="o">-</span> <span class="n">y_score</span> <span class="o">-</span> <span class="n">loggamma</span><span class="p">(</span><span class="n">y_true</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">loglike</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">loglike</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">neg</span><span class="p">:</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">loglike</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">loglike</span></div>


<div class="viewcode-block" id="glm_likelihood_poisson"><a class="viewcode-back" href="../../generated/tsdst.distributions.glm_likelihood_poisson.html#tsdst.distributions.glm_likelihood_poisson">[docs]</a><span class="k">def</span> <span class="nf">glm_likelihood_poisson</span><span class="p">(</span><span class="n">parms</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">lamb</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">l_p</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">neg</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The likelihood for a poisson regression model with a penalty</span>
<span class="sd">    term (can accept any norm, default is 1 for L1).</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    parms : numpy array (numeric)</span>
<span class="sd">        The coefficients (including intercept, which is first)</span>
<span class="sd">    X : numpy array (numeric)</span>
<span class="sd">        The independent variables (or feature matrix), where the first column</span>
<span class="sd">        is a dummy column of 1&#39;s (for the intercept).</span>
<span class="sd">    Y : numpy array or pandas dataframe</span>
<span class="sd">        The response value (should be an integer &gt;= 0).</span>
<span class="sd">    lamb : int, optional</span>
<span class="sd">        The size of the penalty (lambda). Note this is the inverse of the</span>
<span class="sd">        common sklearn parameter C (i.e. C=1/lambda. The default is 1.</span>
<span class="sd">    l_p : int, optional</span>
<span class="sd">        The mathematical norm to be applied to the coefficients.</span>
<span class="sd">        The default is 1, representing an L1 penalty.</span>
<span class="sd">    neg : bool, optional</span>
<span class="sd">        Return negative likelihood. The default is True.</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        Return log-likelihood. The default is True.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        The likelihood.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from tsdst.distributions import glm_likelihood_poisson</span>
<span class="sd">    &gt;&gt;&gt; </span>
<span class="sd">    &gt;&gt;&gt; intercept = np.array([3])</span>
<span class="sd">    &gt;&gt;&gt; betas = np.array([2,4,5])</span>
<span class="sd">    &gt;&gt;&gt; params = np.concatenate((intercept, betas))</span>
<span class="sd">    &gt;&gt;&gt; </span>
<span class="sd">    &gt;&gt;&gt; np.random.seed(123)</span>
<span class="sd">    &gt;&gt;&gt; X = np.random.normal(size=(100, 3))</span>
<span class="sd">    &gt;&gt;&gt; X = np.hstack((np.repeat(1, 100).reshape(-1, 1), X))</span>
<span class="sd">    &gt;&gt;&gt; Y = np.round(np.random.uniform(low=0, high=10, size=100))</span>
<span class="sd">    &gt;&gt;&gt; </span>
<span class="sd">    &gt;&gt;&gt; glm_likelihood_poisson(params, X, Y, lamb=1, l_p=1)</span>
<span class="sd">    3287063650.908373</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1">#intercept = parms[0]</span>
    <span class="n">betas</span> <span class="o">=</span> <span class="n">parms</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
    
    <span class="n">mu</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">parms</span><span class="p">)</span>
    
    <span class="n">loglike</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">Y</span><span class="o">*</span><span class="n">mu</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span> <span class="o">-</span> <span class="n">loggamma</span><span class="p">(</span><span class="n">Y</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span> <span class="o">-</span> <span class="n">lamb</span><span class="o">*</span><span class="n">norm</span><span class="p">(</span><span class="n">betas</span><span class="p">,</span> <span class="n">l_p</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">loglike</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">loglike</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">neg</span><span class="p">:</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">loglike</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">loglike</span></div>


<div class="viewcode-block" id="likelihood_gaussian"><a class="viewcode-back" href="../../generated/tsdst.distributions.likelihood_gaussian.html#tsdst.distributions.likelihood_gaussian">[docs]</a><span class="k">def</span> <span class="nf">likelihood_gaussian</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="n">neg</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The likelihood for a normal(ish) output or gaussian model.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : numpy array (numeric)</span>
<span class="sd">        The true values (the normal observations).</span>
<span class="sd">    y_score : numpy array or pandas dataframe</span>
<span class="sd">        The estimated value/values (mean of the normal distribution).</span>
<span class="sd">    neg : bool, optional</span>
<span class="sd">        Return negative likelihood. The default is True.</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        Return log-likelihood. The default is True.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        The likelihood.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">sigma</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># The MLE estimate of sigma</span>
        <span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">y_true</span> <span class="o">-</span> <span class="n">y_score</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>

    <span class="n">loglike</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="o">-</span><span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">sigma</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span><span class="o">*</span><span class="p">((</span><span class="n">y_true</span> <span class="o">-</span> <span class="n">y_score</span><span class="p">)</span> <span class="o">/</span> <span class="n">sigma</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">loglike</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">loglike</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">neg</span><span class="p">:</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">loglike</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">loglike</span></div>


<div class="viewcode-block" id="glm_likelihood_gaussian"><a class="viewcode-back" href="../../generated/tsdst.distributions.glm_likelihood_gaussian.html#tsdst.distributions.glm_likelihood_gaussian">[docs]</a><span class="k">def</span> <span class="nf">glm_likelihood_gaussian</span><span class="p">(</span><span class="n">parms</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">lamb</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">l_p</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">neg</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                            <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The likelihood for a gaussian regression model with a penalty</span>
<span class="sd">    term (can accept any norm, default is 1 for L1).</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    parms : numpy array (numeric)</span>
<span class="sd">        The coefficients (including intercept, which is first)</span>
<span class="sd">    X : numpy array (numeric)</span>
<span class="sd">        The independent variables (or feature matrix), where the first column</span>
<span class="sd">        is a dummy column of 1&#39;s (for the intercept).</span>
<span class="sd">    Y : numpy array or pandas dataframe</span>
<span class="sd">        The response value (should be 0 or 1, but could be float as well if </span>
<span class="sd">        you&#39;re willing to deal with those consequences).</span>
<span class="sd">    lamb : int, optional</span>
<span class="sd">        The size of the penalty (lambda). Note this is the inverse of the</span>
<span class="sd">        common sklearn parameter C (i.e. C=1/lambda. The default is 1.</span>
<span class="sd">    l_p : int, optional</span>
<span class="sd">        The mathematical norm to be applied to the coefficients.</span>
<span class="sd">        The default is 1, representing an L1 penalty.</span>
<span class="sd">    neg : bool, optional</span>
<span class="sd">        Return negative likelihood. The default is True.</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        Return log-likelihood. The default is True.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        The likelihood.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from tsdst.distributions import glm_likelihood_gaussian</span>
<span class="sd">    &gt;&gt;&gt; </span>
<span class="sd">    &gt;&gt;&gt; intercept = np.array([3])</span>
<span class="sd">    &gt;&gt;&gt; betas = np.array([2,4,5])</span>
<span class="sd">    &gt;&gt;&gt; params = np.concatenate((intercept, betas))</span>
<span class="sd">    &gt;&gt;&gt; </span>
<span class="sd">    &gt;&gt;&gt; np.random.seed(123)</span>
<span class="sd">    &gt;&gt;&gt; X = np.random.normal(size=(100, 3))</span>
<span class="sd">    &gt;&gt;&gt; X = np.hstack((np.repeat(1, 100).reshape(-1, 1), X))</span>
<span class="sd">    &gt;&gt;&gt; Y = np.random.normal(size=100)</span>
<span class="sd">    &gt;&gt;&gt; </span>
<span class="sd">    &gt;&gt;&gt; glm_likelihood_gaussian(params, X, Y, lamb=1, l_p=1)</span>
<span class="sd">    360.17670995853115</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1">#intercept = parms[0]</span>
    <span class="n">betas</span> <span class="o">=</span> <span class="n">parms</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
    
    <span class="n">mu</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">parms</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">sigma</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># The MLE estimate of sigma (df is nobs - num_params (including intercept))</span>
        <span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">Y</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">parms</span><span class="p">)))</span>

    <span class="c1"># intercept does not get penalized</span>
    <span class="n">loglike</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="o">-</span><span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">sigma</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span><span class="o">*</span><span class="p">((</span><span class="n">Y</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span> <span class="o">/</span> <span class="n">sigma</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span> <span class="o">-</span> <span class="n">lamb</span><span class="o">*</span><span class="n">norm</span><span class="p">(</span><span class="n">betas</span><span class="p">,</span> <span class="n">l_p</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="ow">not</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">loglike</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">loglike</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">neg</span><span class="p">:</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">loglike</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">loglike</span></div>
    

<div class="viewcode-block" id="exponential_mle"><a class="viewcode-back" href="../../generated/tsdst.distributions.exponential_mle.html#tsdst.distributions.exponential_mle">[docs]</a><span class="k">def</span> <span class="nf">exponential_mle</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">censored</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Maximum Likelihood Estimate of an exponential distribution (with an</span>
<span class="sd">    option for right-censoring).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : numpy array</span>
<span class="sd">        The data for the exponential distribution (usually time between events,</span>
<span class="sd">        or similar).</span>
<span class="sd">    censored : numpy array</span>
<span class="sd">        An array of boolean values where 1 means the event occured and 0 means</span>
<span class="sd">        the event is censored (right).</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    list</span>
<span class="sd">        A list containing (in order) the MLE, the standard error, and the </span>
<span class="sd">        95% confidence interval for the estimate.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">censored</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">censored</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">nf</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">size</span>
    <span class="n">rate</span> <span class="o">=</span> <span class="n">nf</span><span class="o">/</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">f</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">c</span><span class="p">))</span>
    <span class="n">se</span> <span class="o">=</span> <span class="n">rate</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">nf</span><span class="p">)</span>
    <span class="n">params_ci</span> <span class="o">=</span> <span class="p">(</span><span class="n">rate</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span><span class="o">*</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="mf">0.95</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="n">se</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">rate</span><span class="p">,</span> <span class="n">se</span><span class="p">,</span> <span class="n">params_ci</span><span class="p">]</span></div>


<span class="c1"># #########################################</span>
<span class="c1"># ########## Posterior Functions ##########</span>
<span class="c1"># #########################################</span>


<div class="viewcode-block" id="posterior_logreg_lasso"><a class="viewcode-back" href="../../generated/tsdst.distributions.posterior_logreg_lasso.html#tsdst.distributions.posterior_logreg_lasso">[docs]</a><span class="k">def</span> <span class="nf">posterior_logreg_lasso</span><span class="p">(</span><span class="n">parms</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">l_scale</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">neg</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The posterior density for a logistic regression model with an L1 penalty</span>
<span class="sd">    term.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    parms : numpy array (numeric)</span>
<span class="sd">        The coefficients (including intercept, which is first)</span>
<span class="sd">    X : numpy array (numeric)</span>
<span class="sd">        The independent variables (or feature matrix), where the first column</span>
<span class="sd">        is a dummy column of 1&#39;s (for the intercept).</span>
<span class="sd">    Y : numpy array or pandas dataframe</span>
<span class="sd">        The response value (should be 0 or 1, but could be float as well if </span>
<span class="sd">        you&#39;re willing to deal with those consequences).</span>
<span class="sd">    l_scale : float, optional</span>
<span class="sd">        The value of the scale parameter in the Laplace distribution.</span>
<span class="sd">        A common choice for the laplace prior is scale = 2/lambda, </span>
<span class="sd">        because it can be shown that this is the MAP estimate where</span>
<span class="sd">        a laplace prior is equivalent to performing lasso regression.</span>
<span class="sd">        lambda is the L1 penalty, or scale = 2*C (where C is the penalty term</span>
<span class="sd">        in sklearn).</span>
<span class="sd">        </span>
<span class="sd">        I find that when scale == C, you get more similar results to</span>
<span class="sd">        the model output in sklearn, and based on</span>
<span class="sd">        my research into their implementation, I think it is because the</span>
<span class="sd">        sklearn implementation actually scales lambda by 1/2 (see the user</span>
<span class="sd">        guide here for more details:</span>
<span class="sd">        https://scikit-learn.org/stable/modules/linear_model.html),</span>
<span class="sd">        but i&#39;m not 100% sure on this. This parameterization is similar to</span>
<span class="sd">        scale = stddev/lambda or scale = stddev*C, where they set stddev to</span>
<span class="sd">        1 instead of 2. The default value is 1.</span>
<span class="sd">    neg : bool, optional</span>
<span class="sd">        Return negative density. The default value is False.</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        Return log-density. The default value is True.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        The posterior density (height of the posterior density)</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    ap_logreg_lasso</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from tsdst.distributions import posterior_logreg_lasso</span>
<span class="sd">    &gt;&gt;&gt; </span>
<span class="sd">    &gt;&gt;&gt; intercept = np.array([3])</span>
<span class="sd">    &gt;&gt;&gt; betas = np.array([2,4,5])</span>
<span class="sd">    &gt;&gt;&gt; params = np.concatenate((intercept, betas))</span>
<span class="sd">    &gt;&gt;&gt; </span>
<span class="sd">    &gt;&gt;&gt; np.random.seed(123)</span>
<span class="sd">    &gt;&gt;&gt; X = np.random.normal(size=(100, 3))</span>
<span class="sd">    &gt;&gt;&gt; X = np.hstack((np.repeat(1, 100).reshape(-1, 1), X))</span>
<span class="sd">    &gt;&gt;&gt; Y = np.round(np.random.uniform(low=0, high=1, size=100))</span>
<span class="sd">    &gt;&gt;&gt; </span>
<span class="sd">    &gt;&gt;&gt; posterior_logreg_lasso(params, X, Y)</span>
<span class="sd">    -400.881783704988</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_mu</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">n_sigma</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">l_loc</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="n">intercept</span> <span class="o">=</span> <span class="n">parms</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">betas</span> <span class="o">=</span> <span class="n">parms</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
    
    <span class="n">mu</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">parms</span><span class="p">)</span>
    <span class="n">Ypred</span> <span class="o">=</span> <span class="mf">1.0</span><span class="o">/</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">mu</span><span class="p">))</span>
    <span class="n">like</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">Y</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">Ypred</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">Y</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">Ypred</span><span class="p">))</span>
    <span class="c1"># normal prior on the intercept</span>
    <span class="n">int_prior</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">2.0</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">n_sigma</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span><span class="o">*</span><span class="p">((</span><span class="n">intercept</span> <span class="o">-</span> <span class="n">n_mu</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_sigma</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="c1"># Laplace prior </span>
    <span class="n">parm_prior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">l_scale</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">betas</span> <span class="o">-</span> <span class="n">l_loc</span><span class="p">)</span><span class="o">/</span><span class="n">l_scale</span><span class="p">))</span>
    <span class="n">post</span> <span class="o">=</span> <span class="n">like</span> <span class="o">+</span> <span class="n">parm_prior</span> <span class="o">+</span> <span class="n">int_prior</span> 
    
    <span class="k">if</span> <span class="ow">not</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">post</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">post</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">neg</span><span class="p">:</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">post</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">post</span></div>


<div class="viewcode-block" id="ap_logreg_lasso"><a class="viewcode-back" href="../../generated/tsdst.distributions.ap_logreg_lasso.html#tsdst.distributions.ap_logreg_lasso">[docs]</a><span class="k">def</span> <span class="nf">ap_logreg_lasso</span><span class="p">(</span><span class="n">parms</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">l_scale</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">neg</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The posterior density for a logistic regression model with an L1 penalty</span>
<span class="sd">    term. However, unlike the posterior_logreg_lasso function, this is made to</span>
<span class="sd">    adaptively learn the optimal L1 penalty. Therefore, the L1 penalty is</span>
<span class="sd">    in the parms variable, at the end of the array.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    parms : numpy array (numeric)</span>
<span class="sd">        The model coefficients (including intercept, which is first, and the</span>
<span class="sd">        scale of the laplace distribution, which is last)</span>
<span class="sd">    X : numpy array (numeric)</span>
<span class="sd">        The independent variables (or feature matrix), where the first column</span>
<span class="sd">        is a dummy column of 1&#39;s (for the intercept).</span>
<span class="sd">    Y : numpy array or pandas dataframe</span>
<span class="sd">        The response value (should be 0 or 1, but could be float as well if </span>
<span class="sd">        you&#39;re willing to deal with those consequences).</span>
<span class="sd">    l_scale : float, optional</span>
<span class="sd">        ---THIS IS NOT USED. ONLY HERE FOR CONVENIENCE OF THE USER WHEN</span>
<span class="sd">        EXPERIMENTING BETWEEN THE ADAPTIVE AND NON-ADAPTIVE VERSIONS--- </span>
<span class="sd">        The value of the scale parameter in the Laplace distribution.</span>
<span class="sd">        A common choice for the laplace prior is scale = 2/lambda, </span>
<span class="sd">        because it can be shown that this is the MAP estimate where</span>
<span class="sd">        a laplace prior is equivalent to performing lasso regression.</span>
<span class="sd">        lambda is the L1 penalty, or scale = 2*C (where C is the penalty term</span>
<span class="sd">        in sklearn).</span>
<span class="sd">        </span>
<span class="sd">        I find that when scale == C, you get more similar results to</span>
<span class="sd">        the model output in sklearn, and based on</span>
<span class="sd">        my research into their implementation, I think it is because the</span>
<span class="sd">        sklearn implementation actually scales lambda by 1/2 (see the user</span>
<span class="sd">        guide here for more details:</span>
<span class="sd">        https://scikit-learn.org/stable/modules/linear_model.html),</span>
<span class="sd">        but i&#39;m not 100% sure on this. This parameterization is similar to</span>
<span class="sd">        scale = stddev/lambda or scale = stddev*C, where they set stddev to</span>
<span class="sd">        1 instead of 2. The default value is 1.</span>
<span class="sd">    neg : bool, optional</span>
<span class="sd">        Return negative density. The default value is False.</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        Return log-density. The default value is True.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        The posterior density (height of the posterior density)</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    posterior_logreg_lasso</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from tsdst.distributions import ap_logreg_lasso</span>
<span class="sd">    &gt;&gt;&gt; </span>
<span class="sd">    &gt;&gt;&gt; intercept = np.array([3])</span>
<span class="sd">    &gt;&gt;&gt; betas = np.array([2,4,5])</span>
<span class="sd">    &gt;&gt;&gt; scale_param = np.array([1])</span>
<span class="sd">    &gt;&gt;&gt; params = np.concatenate((intercept, betas, scale_param))</span>
<span class="sd">    &gt;&gt;&gt; </span>
<span class="sd">    &gt;&gt;&gt; np.random.seed(123)</span>
<span class="sd">    &gt;&gt;&gt; X = np.random.normal(size=(100, 3))</span>
<span class="sd">    &gt;&gt;&gt; X = np.hstack((np.repeat(1, 100).reshape(-1, 1), X))</span>
<span class="sd">    &gt;&gt;&gt; Y = np.round(np.random.uniform(low=0, high=1, size=100))</span>
<span class="sd">    &gt;&gt;&gt; </span>
<span class="sd">    &gt;&gt;&gt; ap_logreg_lasso(params, X, Y)</span>
<span class="sd">    -395.3461032130849</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_mu</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">n_sigma</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">l_loc</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="c1"># assuming an exponential prior for the scale parameter of the laplace</span>
    <span class="c1"># mean/scale of 0.38 seemed to work well for these experiments</span>
    <span class="n">l_scale_rate</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="mf">0.38</span>
    
    <span class="n">intercept</span> <span class="o">=</span> <span class="n">parms</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">betas</span> <span class="o">=</span> <span class="n">parms</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">l_scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">parms</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    
    <span class="n">mu</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">parms</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">)</span>
    <span class="n">Ypred</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">mu</span><span class="p">))</span>
    <span class="n">like</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">Y</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">Ypred</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">Y</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">Ypred</span><span class="p">))</span>
    <span class="c1"># normal prior on the intercept</span>
    <span class="n">int_prior</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">2.0</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">n_sigma</span><span class="p">)</span> <span class="o">-</span> <span class="p">(((</span><span class="n">intercept</span> <span class="o">-</span> <span class="n">n_mu</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">n_sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">))))</span>
    <span class="c1"># Laplace prior for Coefficient</span>
    <span class="n">parm_prior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">l_scale</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">betas</span> <span class="o">-</span> <span class="n">l_loc</span><span class="p">)</span><span class="o">/</span><span class="n">l_scale</span><span class="p">))</span>
    <span class="c1"># exponential prior for scale parameter</span>
    <span class="n">scale_prior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">l_scale_rate</span><span class="p">)</span> <span class="o">-</span> <span class="n">l_scale_rate</span> <span class="o">*</span> <span class="n">l_scale</span>
    <span class="c1"># post = likelihood + laplace prior + jacobian for laplace scale + laplace scale prior</span>
    <span class="n">post</span> <span class="o">=</span> <span class="n">like</span> <span class="o">+</span> <span class="n">int_prior</span> <span class="o">+</span> <span class="n">parm_prior</span> <span class="o">+</span> <span class="n">parms</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">scale_prior</span>
    
    <span class="k">if</span> <span class="ow">not</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">post</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">post</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">neg</span><span class="p">:</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">post</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">post</span></div>


<span class="k">def</span> <span class="nf">ap_poisson_lasso</span><span class="p">(</span><span class="n">parms</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">l_scale</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">neg</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The posterior density for a poisson regression model with an L1 penalty</span>
<span class="sd">    term. However, unlike the poisson_regression function, this is made to</span>
<span class="sd">    adaptively learn the optimal L1 penalty. Therefore, the L1 penalty is</span>
<span class="sd">    in the parms variable, at the end of the array.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    parms : numpy array (numeric)</span>
<span class="sd">        The model coefficients (including intercept, which is first, and the</span>
<span class="sd">        scale of the laplace distribution, which is last)</span>
<span class="sd">    X : numpy array (numeric)</span>
<span class="sd">        The independent variables (or feature matrix), where the first column</span>
<span class="sd">        is a dummy column of 1&#39;s (for the intercept).</span>
<span class="sd">    Y : numpy array or pandas dataframe</span>
<span class="sd">        The response value (should be an integer &gt;= 0).</span>
<span class="sd">    l_scale : float, optional</span>
<span class="sd">        ---THIS IS NOT USED. ONLY HERE FOR CONVENIENCE OF THE USER WHEN</span>
<span class="sd">        EXPERIMENTING BETWEEN THE ADAPTIVE AND NON-ADAPTIVE VERSIONS--- </span>
<span class="sd">        The value of the scale parameter in the Laplace distribution.</span>
<span class="sd">        A common choice for the laplace prior is scale = 2/lambda, </span>
<span class="sd">        because it can be shown that this is the MAP estimate where</span>
<span class="sd">        a laplace prior is equivalent to performing lasso regression.</span>
<span class="sd">        lambda is the L1 penalty, or scale = 2*C (where C is the penalty term</span>
<span class="sd">        in sklearn).</span>
<span class="sd">        </span>
<span class="sd">        I find that when scale == C, you get more similar results to</span>
<span class="sd">        the model output in sklearn, and based on</span>
<span class="sd">        my research into their implementation, I think it is because the</span>
<span class="sd">        sklearn implementation actually scales lambda by 1/2 (see the user</span>
<span class="sd">        guide here for more details:</span>
<span class="sd">        https://scikit-learn.org/stable/modules/linear_model.html),</span>
<span class="sd">        but i&#39;m not 100% sure on this. This parameterization is similar to</span>
<span class="sd">        scale = stddev/lambda or scale = stddev*C, where they set stddev to</span>
<span class="sd">        1 instead of 2. The default value is 1.</span>
<span class="sd">    neg : bool, optional</span>
<span class="sd">        Return negative density. The default value is False.</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        Return log-density. The default value is True.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        The posterior density (height of the posterior density)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_sigma</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">l_loc</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="c1"># assuming an exponential prior for the scale parameter of the laplace</span>
    <span class="c1"># mean/scale of 0.38 seemed to work well for these experiments</span>
    <span class="n">l_scale_rate</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="mf">0.38</span>
    
    <span class="n">intercept</span> <span class="o">=</span> <span class="n">parms</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">betas</span> <span class="o">=</span> <span class="n">parms</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">l_scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">parms</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    
    <span class="n">mu</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">parms</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    
    <span class="n">like</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">Y</span><span class="o">*</span><span class="n">mu</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span> <span class="o">-</span> <span class="n">loggamma</span><span class="p">(</span><span class="n">Y</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
    <span class="c1"># normal prior on the intercept</span>
    <span class="n">int_prior</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">2.0</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">n_sigma</span><span class="p">)</span> <span class="o">-</span> <span class="p">(((</span><span class="n">intercept</span> <span class="o">-</span> <span class="n">l_loc</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mf">2.0</span><span class="o">*</span><span class="p">(</span><span class="n">n_sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">))))</span>
    <span class="c1"># Laplace prior </span>
    <span class="c1">#parm_prior = np.sum(-np.log(2*l_scale) - (np.abs(betas - l_loc)/l_scale))</span>
    <span class="c1"># Normal prior</span>
    <span class="n">parm_prior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">2.0</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">l_scale</span><span class="p">)</span> <span class="o">-</span> <span class="p">(((</span><span class="n">betas</span> <span class="o">-</span> <span class="n">l_loc</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mf">2.0</span><span class="o">*</span><span class="p">(</span><span class="n">l_scale</span><span class="o">**</span><span class="mi">2</span><span class="p">))))</span>
    
    <span class="c1"># exponential prior for scale parameter</span>
    <span class="n">scale_prior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">l_scale_rate</span><span class="p">)</span> <span class="o">-</span> <span class="n">l_scale_rate</span> <span class="o">*</span> <span class="n">l_scale</span>
    <span class="c1"># post = likelihood + laplace prior + jacobian for laplace scale + laplace scale prior</span>
    
    <span class="n">post</span> <span class="o">=</span> <span class="n">like</span> <span class="o">+</span> <span class="n">parm_prior</span> <span class="o">+</span> <span class="n">int_prior</span> <span class="o">+</span> <span class="n">parms</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">scale_prior</span>
    
    <span class="k">if</span> <span class="ow">not</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">post</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">post</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">neg</span><span class="p">:</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">post</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">post</span>


<div class="viewcode-block" id="ap_poisson_lasso_od"><a class="viewcode-back" href="../../generated/tsdst.distributions.ap_poisson_lasso_od.html#tsdst.distributions.ap_poisson_lasso_od">[docs]</a><span class="k">def</span> <span class="nf">ap_poisson_lasso_od</span><span class="p">(</span><span class="n">parms</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">l_scale</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">neg</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The posterior density for a poisson regression model with an L1 penalty</span>
<span class="sd">    term. However, unlike the poisson_regression function, this is made to</span>
<span class="sd">    adaptively learn the optimal L1 penalty. Therefore, the L1 penalty is</span>
<span class="sd">    in the parms variable, at the end of the array. This function also attempts</span>
<span class="sd">    to adaptively account for over-dispersion.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    parms : numpy array (numeric)</span>
<span class="sd">        The model coefficients (including intercept, which is first, and the</span>
<span class="sd">        scale of the laplace distribution, which is last)</span>
<span class="sd">    X : numpy array (numeric)</span>
<span class="sd">        The independent variables (or feature matrix), where the first column</span>
<span class="sd">        is a dummy column of 1&#39;s (for the intercept).</span>
<span class="sd">    Y : numpy array or pandas dataframe</span>
<span class="sd">        The response value (should be an integer &gt;= 0).</span>
<span class="sd">    l_scale : float, optional</span>
<span class="sd">        ---THIS IS NOT USED. ONLY HERE FOR CONVENIENCE OF THE USER WHEN</span>
<span class="sd">        EXPERIMENTING BETWEEN THE ADAPTIVE AND NON-ADAPTIVE VERSIONS--- </span>
<span class="sd">        The value of the scale parameter in the Laplace distribution.</span>
<span class="sd">        A common choice for the laplace prior is scale = 2/lambda, </span>
<span class="sd">        because it can be shown that this is the MAP estimate where</span>
<span class="sd">        a laplace prior is equivalent to performing lasso regression.</span>
<span class="sd">        lambda is the L1 penalty, or scale = 2*C (where C is the penalty term</span>
<span class="sd">        in sklearn).</span>
<span class="sd">        </span>
<span class="sd">        I find that when scale == C, you get more similar results to</span>
<span class="sd">        the model output in sklearn, and based on</span>
<span class="sd">        my research into their implementation, I think it is because the</span>
<span class="sd">        sklearn implementation actually scales lambda by 1/2 (see the user</span>
<span class="sd">        guide here for more details:</span>
<span class="sd">        https://scikit-learn.org/stable/modules/linear_model.html),</span>
<span class="sd">        but i&#39;m not 100% sure on this. This parameterization is similar to</span>
<span class="sd">        scale = stddev/lambda or scale = stddev*C, where they set stddev to</span>
<span class="sd">        1 instead of 2. The default value is 1.</span>
<span class="sd">    neg : bool, optional</span>
<span class="sd">        Return negative density. The default value is False.</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        Return log-density. The default value is True.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        The posterior density (height of the posterior density)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_sigma</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="c1"># I think in pretty much every case you want this zero, so l_loc applies</span>
    <span class="c1"># to both the normal mu parameter and the laplace location parameter</span>
    <span class="n">l_loc</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="c1"># assuming an exponential prior for the scale parameter of the laplace</span>
    <span class="c1"># mean/scale of 0.38 seemed to work well for these experiments</span>
    <span class="n">l_scale_rate</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="mf">0.38</span>
    
    <span class="n">intercept</span> <span class="o">=</span> <span class="n">parms</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">betas</span> <span class="o">=</span> <span class="n">parms</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">l_scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">parms</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span>
    <span class="n">delta</span> <span class="o">=</span> <span class="n">parms</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="n">mu</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">parms</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span> <span class="o">-</span> <span class="n">parms</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">lamda</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>
    
    <span class="n">like</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">mu</span> <span class="o">+</span> <span class="p">(</span><span class="n">Y</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">lamda</span> <span class="o">+</span> <span class="n">delta</span><span class="o">*</span><span class="n">Y</span><span class="p">)</span> <span class="o">-</span> <span class="n">lamda</span> <span class="o">-</span> <span class="n">delta</span><span class="o">*</span><span class="n">Y</span> <span class="o">-</span> <span class="n">loggamma</span><span class="p">(</span><span class="n">Y</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>

    <span class="c1"># normal prior on the intercept</span>
    <span class="n">int_prior</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">2.0</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">n_sigma</span><span class="p">)</span> <span class="o">-</span> <span class="p">(((</span><span class="n">intercept</span> <span class="o">-</span> <span class="n">l_loc</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mf">2.0</span><span class="o">*</span><span class="p">(</span><span class="n">n_sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">))))</span>
    <span class="c1"># Laplace prior </span>
    <span class="c1">#parm_prior = np.sum(-np.log(2*l_scale) - (np.abs(betas - l_loc)/l_scale))</span>
    <span class="c1"># Normal prior</span>
    <span class="n">parm_prior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">2.0</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">l_scale</span><span class="p">)</span> <span class="o">-</span> <span class="p">(((</span><span class="n">betas</span> <span class="o">-</span> <span class="n">l_loc</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mf">2.0</span><span class="o">*</span><span class="p">(</span><span class="n">l_scale</span><span class="o">**</span><span class="mi">2</span><span class="p">))))</span>
    
    <span class="c1"># exponential prior for scale parameter</span>
    <span class="n">scale_prior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">l_scale_rate</span><span class="p">)</span> <span class="o">-</span> <span class="n">l_scale_rate</span> <span class="o">*</span> <span class="n">l_scale</span>
    <span class="c1"># post = likelihood + laplace prior + jacobian for laplace scale + laplace scale prior</span>
    
    <span class="n">post</span> <span class="o">=</span> <span class="n">like</span> <span class="o">+</span> <span class="n">parm_prior</span> <span class="o">+</span> <span class="n">int_prior</span> <span class="o">+</span> <span class="n">parms</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="n">scale_prior</span>
    
    <span class="k">if</span> <span class="ow">not</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">post</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">post</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">neg</span><span class="p">:</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">post</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">post</span></div>


<div class="viewcode-block" id="posterior_poisson_lasso"><a class="viewcode-back" href="../../generated/tsdst.distributions.posterior_poisson_lasso.html#tsdst.distributions.posterior_poisson_lasso">[docs]</a><span class="k">def</span> <span class="nf">posterior_poisson_lasso</span><span class="p">(</span><span class="n">parms</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">l_scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">neg</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The posterior density for a poisson regression model with an L1 penalty</span>
<span class="sd">    term.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    parms : numpy array (numeric)</span>
<span class="sd">        The model coefficients (including intercept, which is first, and the</span>
<span class="sd">        scale of the laplace distribution, which is last)</span>
<span class="sd">    X : numpy array (numeric)</span>
<span class="sd">        The independent variables (or feature matrix), where the first column</span>
<span class="sd">        is a dummy column of 1&#39;s (for the intercept).</span>
<span class="sd">    Y : numpy array or pandas dataframe</span>
<span class="sd">        The response value (should be an integer &gt;= 0).</span>
<span class="sd">    l_scale : float, optional</span>
<span class="sd">        The value of the scale parameter in the Laplace distribution.</span>
<span class="sd">        A common choice for the laplace prior is scale = 2/lambda, </span>
<span class="sd">        because it can be shown that this is the MAP estimate where</span>
<span class="sd">        a laplace prior is equivalent to performing lasso regression.</span>
<span class="sd">        lambda is the L1 penalty, or scale = 2*C (where C is the penalty term</span>
<span class="sd">        in sklearn).</span>
<span class="sd">        </span>
<span class="sd">        I find that when scale == C, you get more similar results to</span>
<span class="sd">        the model output in sklearn, and based on</span>
<span class="sd">        my research into their implementation, I think it is because the</span>
<span class="sd">        sklearn implementation actually scales lambda by 1/2 (see the user</span>
<span class="sd">        guide here for more details:</span>
<span class="sd">        https://scikit-learn.org/stable/modules/linear_model.html),</span>
<span class="sd">        but i&#39;m not 100% sure on this. This parameterization is similar to</span>
<span class="sd">        scale = stddev/lambda or scale = stddev*C, where they set stddev to</span>
<span class="sd">        1 instead of 2. The default value is 1.</span>
<span class="sd">    neg : bool, optional</span>
<span class="sd">        Return negative density. The default value is False.</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        Return log-density. The default value is True.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        The posterior density (height of the posterior density)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_sigma</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="c1"># I think in pretty much every case you want this zero, so l_loc applies</span>
    <span class="c1"># to both the normal mu parameter and the laplace location parameter</span>
    <span class="n">l_loc</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="n">intercept</span> <span class="o">=</span> <span class="n">parms</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">betas</span> <span class="o">=</span> <span class="n">parms</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
    
    <span class="n">mu</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">parms</span><span class="p">)</span>
    
    <span class="n">like</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">Y</span><span class="o">*</span><span class="n">mu</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span> <span class="o">-</span> <span class="n">loggamma</span><span class="p">(</span><span class="n">Y</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
    <span class="c1"># normal prior on the intercept</span>
    <span class="n">int_prior</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">2.0</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">n_sigma</span><span class="p">)</span> <span class="o">-</span> <span class="p">(((</span><span class="n">intercept</span> <span class="o">-</span> <span class="n">l_loc</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mf">2.0</span><span class="o">*</span><span class="p">(</span><span class="n">n_sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">))))</span>
    <span class="c1"># Laplace prior </span>
    <span class="c1">#parm_prior = np.sum(-np.log(2*l_scale) - (np.abs(betas - l_loc)/l_scale))</span>
    <span class="c1"># Normal prior</span>
    <span class="n">coef_prior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">2.0</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">l_scale</span><span class="p">)</span> <span class="o">-</span> <span class="p">(((</span><span class="n">betas</span> <span class="o">-</span> <span class="n">l_loc</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mf">2.0</span><span class="o">*</span><span class="p">(</span><span class="n">l_scale</span><span class="o">**</span><span class="mi">2</span><span class="p">))))</span>
    
    <span class="n">post</span> <span class="o">=</span> <span class="n">like</span> <span class="o">+</span> <span class="n">coef_prior</span> <span class="o">+</span> <span class="n">int_prior</span> 
    
    <span class="k">if</span> <span class="ow">not</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">post</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">post</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">neg</span><span class="p">:</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">post</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">post</span></div>


<div class="viewcode-block" id="posterior_poisson_lasso_od"><a class="viewcode-back" href="../../generated/tsdst.distributions.posterior_poisson_lasso_od.html#tsdst.distributions.posterior_poisson_lasso_od">[docs]</a><span class="k">def</span> <span class="nf">posterior_poisson_lasso_od</span><span class="p">(</span><span class="n">parms</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">l_scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">neg</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The posterior density for a poisson regression model with an L1 penalty</span>
<span class="sd">    term. This function also attempts to adaptively account for over-dispersion.</span>
<span class="sd">    </span>
<span class="sd">    Uses a generalized poisson model for the dispersion calculation. See</span>
<span class="sd">    https://journals.sagepub.com/doi/pdf/10.1177/1536867X1201200412</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    parms : numpy array (numeric)</span>
<span class="sd">        The model coefficients (including intercept, which is first, and the</span>
<span class="sd">        scale of the laplace distribution, which is last)</span>
<span class="sd">    X : numpy array (numeric)</span>
<span class="sd">        The independent variables (or feature matrix), where the first column</span>
<span class="sd">        is a dummy column of 1&#39;s (for the intercept).</span>
<span class="sd">    Y : numpy array or pandas dataframe</span>
<span class="sd">        The response value (should be an integer &gt;= 0).</span>
<span class="sd">    l_scale : float, optional</span>
<span class="sd">        The value of the scale parameter in the Laplace distribution.</span>
<span class="sd">        A common choice for the laplace prior is scale = 2/lambda, </span>
<span class="sd">        because it can be shown that this is the MAP estimate where</span>
<span class="sd">        a laplace prior is equivalent to performing lasso regression.</span>
<span class="sd">        lambda is the L1 penalty, or scale = 2*C (where C is the penalty term</span>
<span class="sd">        in sklearn).</span>
<span class="sd">        </span>
<span class="sd">        I find that when scale == C, you get more similar results to</span>
<span class="sd">        the model output in sklearn, and based on</span>
<span class="sd">        my research into their implementation, I think it is because the</span>
<span class="sd">        sklearn implementation actually scales lambda by 1/2 (see the user</span>
<span class="sd">        guide here for more details:</span>
<span class="sd">        https://scikit-learn.org/stable/modules/linear_model.html),</span>
<span class="sd">        but i&#39;m not 100% sure on this. This parameterization is similar to</span>
<span class="sd">        scale = stddev/lambda or scale = stddev*C, where they set stddev to</span>
<span class="sd">        1 instead of 2. The default value is 1.</span>
<span class="sd">    neg : bool, optional</span>
<span class="sd">        Return negative density. The default value is False.</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        Return log-density. The default value is True.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        The posterior density (height of the posterior density)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_sigma</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="c1"># I think in pretty much every case you want this zero, so l_loc applies</span>
    <span class="c1"># to both the normal mu parameter and the laplace location parameter</span>
    <span class="n">l_loc</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="n">intercept</span> <span class="o">=</span> <span class="n">parms</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">betas</span> <span class="o">=</span> <span class="n">parms</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>   
    
    <span class="c1"># alternative formulation:</span>
    <span class="c1"># see: https://journals.sagepub.com/doi/pdf/10.1177/1536867X1201200412</span>
    
    <span class="c1"># custom bound on delta so it is strictly less than 1</span>
    <span class="c1">#delta = np.log(1/(1+np.exp(-parms[-1]))) + 1</span>
    <span class="c1"># else:</span>
    <span class="n">delta</span> <span class="o">=</span> <span class="n">parms</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="n">lamda</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">parms</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">lamda</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">delta</span><span class="p">)</span>
    
    <span class="n">log_theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
    <span class="n">like</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">log_theta</span> <span class="o">+</span> <span class="n">xlogy</span><span class="p">(</span><span class="n">Y</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">theta</span> <span class="o">+</span> <span class="n">delta</span><span class="o">*</span><span class="n">Y</span><span class="p">)</span> <span class="o">-</span> <span class="n">theta</span> <span class="o">-</span> <span class="n">delta</span><span class="o">*</span><span class="n">Y</span> <span class="o">-</span> <span class="n">loggamma</span><span class="p">(</span><span class="n">Y</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
       
    <span class="c1"># normal prior on the intercept</span>
    <span class="n">int_prior</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">2.0</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">n_sigma</span><span class="p">)</span> <span class="o">-</span> <span class="p">(((</span><span class="n">intercept</span> <span class="o">-</span> <span class="n">l_loc</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mf">2.0</span><span class="o">*</span><span class="p">(</span><span class="n">n_sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">))))</span>
    <span class="c1"># Laplace prior on beta</span>
    <span class="n">coef_prior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">l_scale</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">betas</span> <span class="o">-</span> <span class="n">l_loc</span><span class="p">)</span><span class="o">/</span><span class="n">l_scale</span><span class="p">))</span>
    <span class="c1"># Normal prior on beta</span>
    <span class="c1">#coef_prior = np.sum(-0.5*np.log(2.0*np.pi) - np.log(l_scale) - (((betas - l_loc)**2) / (2.0*(l_scale**2))))</span>
    
    <span class="c1">## prior on delta</span>
    <span class="c1"># normal</span>
    <span class="n">delta_prior</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">2.0</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">0.4</span><span class="p">)</span> <span class="o">-</span> <span class="p">(((</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">delta</span><span class="p">)</span> <span class="o">-</span> <span class="mi">0</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mf">2.0</span><span class="o">*</span><span class="p">(</span><span class="mf">0.4</span><span class="o">**</span><span class="mi">2</span><span class="p">))))</span>
    
    <span class="c1"># jacobian on custom delta transform</span>
    <span class="c1"># delta_jac = -np.log(np.exp(parms[-1]) + 1)</span>

    <span class="n">post</span> <span class="o">=</span> <span class="p">(</span><span class="n">like</span>
            <span class="o">+</span> <span class="n">coef_prior</span>
            <span class="o">+</span> <span class="n">int_prior</span>
            <span class="o">+</span> <span class="n">delta_prior</span>
            <span class="c1">#+ delta_jac</span>
            <span class="p">)</span>
    
    <span class="k">if</span> <span class="ow">not</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">post</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">post</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">neg</span><span class="p">:</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">post</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">post</span></div>


<div class="viewcode-block" id="weibull_regression_post"><a class="viewcode-back" href="../../generated/tsdst.distributions.weibull_regression_post.html#tsdst.distributions.weibull_regression_post">[docs]</a><span class="k">def</span> <span class="nf">weibull_regression_post</span><span class="p">(</span><span class="n">parms</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">status</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">l_scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">neg</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                            <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The posterior density for a weibull regression model with an L1 penalty</span>
<span class="sd">    term. </span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    parms : numpy array (numeric)</span>
<span class="sd">        The model coefficients (including intercept, which is first, and the</span>
<span class="sd">        scale of the laplace distribution, which is last)</span>
<span class="sd">    X : numpy array (numeric)</span>
<span class="sd">        The independent variables (or feature matrix), where the first column</span>
<span class="sd">        is a dummy column of 1&#39;s (for the intercept).</span>
<span class="sd">    Y : numpy array or pandas dataframe</span>
<span class="sd">        The response value (should be 0 or 1, but could be float as well if </span>
<span class="sd">        you&#39;re willing to deal with those consequences).</span>
<span class="sd">    status : numpy array (int, bool) or None</span>
<span class="sd">        Indicates status used for censoring, in this case, right censoring.</span>
<span class="sd">        An array of 1&#39;s and 0&#39;s, such that a 1 indicates an event, and 0 is the</span>
<span class="sd">        censored observation. If None, it will assume there are no censored</span>
<span class="sd">        events. Default is None.</span>
<span class="sd">    l_scale : float, optional</span>
<span class="sd">        The value of the scale parameter in the Laplace distribution.</span>
<span class="sd">        </span>
<span class="sd">        A common choice for the laplace prior is scale = 2/lambda, or</span>
<span class="sd">        scale = 2*C, where lambda is the L1 penalty (regularization strength)</span>
<span class="sd">        and C is the inverse penalty/strength. This is because it can be shown</span>
<span class="sd">        that this is the MAP estimate where a laplace prior is equivalent</span>
<span class="sd">        to performing lasso regression.</span>
<span class="sd">        </span>
<span class="sd">        I find that when scale == C, you get more similar results to</span>
<span class="sd">        the model output in sklearn, and based on</span>
<span class="sd">        my research into their implementation, I think it is because the</span>
<span class="sd">        sklearn implementation actually scales lambda by 1/2 (see the user</span>
<span class="sd">        guide here for more details:</span>
<span class="sd">        https://scikit-learn.org/stable/modules/linear_model.html),</span>
<span class="sd">        but i&#39;m not 100% sure on this, and it deserves more exploration.</span>
<span class="sd">        This parameterization is similar to scale = variance/lambda or</span>
<span class="sd">        scale = variance*C, where they set variance to 1 instead of 2.</span>
<span class="sd">        The default value is 1.</span>
<span class="sd">    neg : bool, optional</span>
<span class="sd">        Return negative density. The default value is False.</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        Return log-density. The default value is True.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        The posterior density (height of the posterior density)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">l_loc</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">n_sigma</span> <span class="o">=</span> <span class="mi">10</span>
    
    <span class="n">intercept</span> <span class="o">=</span> <span class="n">parms</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">betas</span> <span class="o">=</span> <span class="n">parms</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="n">scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">parms</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">logshape</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">parms</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">logshape</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">status</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">status</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="n">fails</span> <span class="o">=</span> <span class="n">Y</span><span class="p">[</span><span class="n">status</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">cens</span> <span class="o">=</span> <span class="n">Y</span><span class="p">[</span><span class="n">status</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">shape_fail</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="n">status</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">shape_cens</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="n">status</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">gshape</span> <span class="o">=</span> <span class="mf">0.01</span>
    <span class="n">gscale</span> <span class="o">=</span> <span class="mf">100.0</span>
    
    <span class="n">xly_1</span> <span class="o">=</span> <span class="n">xlogy</span><span class="p">(</span><span class="n">shape</span> <span class="o">-</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">fails</span><span class="o">/</span><span class="n">scale</span><span class="p">)</span>
    <span class="n">xly_2</span> <span class="o">=</span> <span class="n">xlogy</span><span class="p">(</span><span class="n">gshape</span> <span class="o">-</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">scale</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">fails</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">fail_like</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">shape_fail</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span> <span class="o">+</span> <span class="n">xly_1</span> <span class="o">-</span> <span class="p">(</span><span class="n">fails</span><span class="o">/</span><span class="n">scale</span><span class="p">)</span><span class="o">**</span><span class="n">shape</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">fail_like</span> <span class="o">=</span> <span class="mi">0</span>
        
    <span class="k">if</span> <span class="n">cens</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">cens_like</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">cens</span><span class="o">/</span><span class="n">scale</span><span class="p">)</span><span class="o">**</span><span class="n">shape_cens</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">cens_like</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="c1">#scale prior</span>
    <span class="n">scale_prior</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">loggamma</span><span class="p">(</span><span class="n">gshape</span><span class="p">)</span> <span class="o">+</span> <span class="n">gshape</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">gscale</span><span class="p">))</span> <span class="o">+</span> <span class="n">xly_2</span> <span class="o">-</span> <span class="p">(</span><span class="n">scale</span><span class="o">/</span><span class="n">gscale</span><span class="p">))</span>
    <span class="c1"># normal prior on the intercept</span>
    <span class="n">int_prior</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">2.0</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">n_sigma</span><span class="p">)</span> <span class="o">-</span> <span class="p">(((</span><span class="n">intercept</span> <span class="o">-</span> <span class="n">l_loc</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mf">2.0</span><span class="o">*</span><span class="p">(</span><span class="n">n_sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">))))</span>
    <span class="c1"># Laplace prior </span>
    <span class="n">parm_prior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">l_scale</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">betas</span> <span class="o">-</span> <span class="n">l_loc</span><span class="p">)</span><span class="o">/</span><span class="n">l_scale</span><span class="p">))</span>
    <span class="c1"># Normal prior</span>
    <span class="c1">#parm_prior = np.sum(-0.5*np.log(2.0*np.pi) - np.log(l_scale) - (((betas - l_loc)**2) / (2.0*(l_scale**2))))</span>
    <span class="c1"># assuming uniform for over dispersion prior</span>
    <span class="n">post</span> <span class="o">=</span> <span class="n">fail_like</span> <span class="o">+</span> <span class="n">cens_like</span> <span class="o">+</span> <span class="n">parm_prior</span> <span class="o">+</span> <span class="n">int_prior</span> <span class="o">+</span> <span class="n">scale_prior</span> <span class="o">+</span> <span class="n">parms</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="k">if</span> <span class="ow">not</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">post</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">post</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">neg</span><span class="p">:</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">post</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">post</span></div>


<div class="viewcode-block" id="pois_uniform"><a class="viewcode-back" href="../../generated/tsdst.distributions.pois_uniform.html#tsdst.distributions.pois_uniform">[docs]</a><span class="k">def</span> <span class="nf">pois_uniform</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">count</span><span class="p">,</span> <span class="n">neg</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Posterior density for the Poisson distribution (assuming uniform prior).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    param : float</span>
<span class="sd">        log of the Poisson mean (lambda).</span>
<span class="sd">    count : int, or array of ints</span>
<span class="sd">        count of events (or poisson counts)</span>
<span class="sd">    neg : bool, optional</span>
<span class="sd">        Return negative density. The default value is False.</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        Return log-density. The default value is True.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        The posterior density (height of the posterior density).</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">lmbda</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>
    <span class="n">like</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">count</span> <span class="o">*</span> <span class="n">param</span> <span class="o">-</span> <span class="n">lmbda</span> <span class="o">-</span> <span class="n">loggamma</span><span class="p">(</span><span class="n">count</span> <span class="o">+</span> <span class="mf">1.0</span><span class="p">))</span>
    <span class="n">jac</span> <span class="o">=</span> <span class="n">param</span>
    
    <span class="n">post</span> <span class="o">=</span> <span class="n">like</span> <span class="o">+</span> <span class="n">jac</span>
    
    <span class="k">if</span> <span class="ow">not</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">post</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">post</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">neg</span><span class="p">:</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">post</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">post</span></div>


<div class="viewcode-block" id="pois_gamma"><a class="viewcode-back" href="../../generated/tsdst.distributions.pois_gamma.html#tsdst.distributions.pois_gamma">[docs]</a><span class="k">def</span> <span class="nf">pois_gamma</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">count</span><span class="p">,</span> <span class="n">gshape</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">gscale</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">neg</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Posterior density for the Poisson distribution (assuming gamma prior).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    param : float</span>
<span class="sd">        Log of the Poisson mean (lambda).</span>
<span class="sd">    count : int, or array of ints</span>
<span class="sd">        count of events (or poisson counts)</span>
<span class="sd">    gshape : float</span>
<span class="sd">        shape parameter of the gamma prior</span>
<span class="sd">    gscale : float</span>
<span class="sd">        scale parameter of the gamma prior</span>
<span class="sd">    neg : bool, optional</span>
<span class="sd">        Return negative density. The default value is False.</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        Return log-density. The default value is True.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        The posterior density (height of the posterior density).</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">lmbda</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>
    <span class="n">like</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">count</span> <span class="o">*</span> <span class="n">param</span> <span class="o">-</span> <span class="n">lmbda</span> <span class="o">-</span> <span class="n">loggamma</span><span class="p">(</span><span class="n">count</span> <span class="o">+</span> <span class="mf">1.0</span><span class="p">))</span>
    <span class="n">prior</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">loggamma</span><span class="p">(</span><span class="n">gshape</span><span class="p">)</span> <span class="o">+</span> <span class="n">gshape</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">gscale</span><span class="p">))</span> <span class="o">+</span>
             <span class="n">xlogy</span><span class="p">(</span><span class="n">gshape</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">lmbda</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="n">lmbda</span><span class="o">/</span><span class="n">gscale</span><span class="p">))</span>
    <span class="n">jac</span> <span class="o">=</span> <span class="n">param</span>
    
    <span class="n">post</span> <span class="o">=</span> <span class="n">like</span> <span class="o">+</span> <span class="n">prior</span> <span class="o">+</span> <span class="n">jac</span>
    
    <span class="k">if</span> <span class="ow">not</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">post</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">post</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">neg</span><span class="p">:</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">post</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">post</span></div>


<div class="viewcode-block" id="pois_gamma_ada"><a class="viewcode-back" href="../../generated/tsdst.distributions.pois_gamma_ada.html#tsdst.distributions.pois_gamma_ada">[docs]</a><span class="k">def</span> <span class="nf">pois_gamma_ada</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">count</span><span class="p">,</span> <span class="n">neg</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Posterior density for the Poisson distribution (assuming gamma prior),</span>
<span class="sd">    learns the gamma shape/scale as part of mcmc.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    param : numpy array (float)</span>
<span class="sd">        The log of the Poisson mean (lambda), and the shape/scale</span>
<span class="sd">        of the gamma prior.</span>
<span class="sd">    count : int, or array of ints</span>
<span class="sd">        count of events (or poisson counts)</span>
<span class="sd">    neg : bool, optional</span>
<span class="sd">        Return negative density. The default value is False.</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        Return log-density. The default value is True.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        The posterior density (height of the posterior density).</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">lmbda</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">param</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">gshape</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">param</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">gscale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">param</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
    <span class="n">like</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">count</span> <span class="o">*</span> <span class="n">param</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">lmbda</span> <span class="o">-</span> <span class="n">loggamma</span><span class="p">(</span><span class="n">count</span> <span class="o">+</span> <span class="mf">1.0</span><span class="p">))</span>
    <span class="n">prior</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">loggamma</span><span class="p">(</span><span class="n">gshape</span><span class="p">)</span> <span class="o">+</span> <span class="n">gshape</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">gscale</span><span class="p">))</span> <span class="o">+</span>
             <span class="n">xlogy</span><span class="p">(</span><span class="n">gshape</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">lmbda</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="n">lmbda</span><span class="o">/</span><span class="n">gscale</span><span class="p">))</span>
    <span class="n">jac</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>
    
    <span class="n">post</span> <span class="o">=</span> <span class="n">like</span> <span class="o">+</span> <span class="n">prior</span> <span class="o">+</span> <span class="n">jac</span>
    
    <span class="k">if</span> <span class="ow">not</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">post</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">post</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">neg</span><span class="p">:</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">post</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">post</span></div>


<div class="viewcode-block" id="exp_gamma"><a class="viewcode-back" href="../../generated/tsdst.distributions.exp_gamma.html#tsdst.distributions.exp_gamma">[docs]</a><span class="k">def</span> <span class="nf">exp_gamma</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">status</span><span class="p">,</span> <span class="n">gshape</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">gscale</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">neg</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
              <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Posterior distribution for an exponential likelihood with a gamma prior.</span>
<span class="sd">    Allows for censoring.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    param : float</span>
<span class="sd">        The log of the rate parameter of an exponential distribution.</span>
<span class="sd">    data : numpy array</span>
<span class="sd">        The data for the exponential likelihood (Usually times).</span>
<span class="sd">    status : numpy array</span>
<span class="sd">        An array of binary variables indicating which items are censored (1&#39;s are events, 0&#39;s are unknown). If there</span>
<span class="sd">        are no censored observations, pass an array of 1&#39;s.</span>
<span class="sd">    gshape : float</span>
<span class="sd">        shape parameter of the gamma prior</span>
<span class="sd">    gscale : float</span>
<span class="sd">        scale parameter of the gamma prior</span>
<span class="sd">    neg : bool, optional</span>
<span class="sd">        Return negative density. The default value is False.</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        Return log-density. The default value is True.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    post : float</span>
<span class="sd">        The posterior density.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">status</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">status</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    
    <span class="n">rate</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>
    <span class="n">events</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">status</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">cens</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">status</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">post</span> <span class="o">=</span> <span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">events</span><span class="p">)</span> <span class="o">*</span> <span class="n">param</span><span class="p">)</span> <span class="o">-</span>
            <span class="p">(</span><span class="n">rate</span><span class="o">*</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">events</span><span class="p">)</span> <span class="o">+</span>
                   <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">cens</span><span class="p">)))</span> <span class="o">+</span>
            <span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">loggamma</span><span class="p">(</span><span class="n">gshape</span><span class="p">)</span> <span class="o">+</span> <span class="n">gshape</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">gscale</span><span class="p">))</span> <span class="o">+</span>
             <span class="p">((</span><span class="n">gshape</span> <span class="o">-</span> <span class="mf">1.0</span><span class="p">)</span><span class="o">*</span><span class="n">param</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="n">rate</span><span class="o">/</span><span class="n">gscale</span><span class="p">))</span> <span class="o">+</span>
            <span class="n">param</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">post</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">post</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">neg</span><span class="p">:</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">post</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">post</span></div>


<div class="viewcode-block" id="weibull_gamma"><a class="viewcode-back" href="../../generated/tsdst.distributions.weibull_gamma.html#tsdst.distributions.weibull_gamma">[docs]</a><span class="k">def</span> <span class="nf">weibull_gamma</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">status</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">gshape</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">gscale</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                  <span class="n">neg</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The posterior density for a weibull distribution with a gamma prior.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    param : numpy array (float)</span>
<span class="sd">        The log shape and scale parameters</span>
<span class="sd">    data : numpy array (float)</span>
<span class="sd">        The data being fit</span>
<span class="sd">    status : numpy array (int, or bool), optional</span>
<span class="sd">        Indicates status used for censoring, in this case, right censoring.</span>
<span class="sd">        An array of 1&#39;s and 0&#39;s, such that a 1 indicates an event, and 0 is the</span>
<span class="sd">        censored observation. If None, it will assume there are no censored</span>
<span class="sd">        events. The default is None.</span>
<span class="sd">    gshape : float</span>
<span class="sd">        shape parameter of the gamma prior</span>
<span class="sd">    gscale : float</span>
<span class="sd">        scale parameter of the gamma prior</span>
<span class="sd">    neg : bool, optional</span>
<span class="sd">        Return negative density. The default value is False.</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        Return log-density. The default value is True.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        The posterior density (height of the posterior density).</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">param</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">param</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

    <span class="k">if</span> <span class="n">status</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">status</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="n">fails</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">status</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">cens</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">status</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span>

    <span class="n">xly_1</span> <span class="o">=</span> <span class="p">(</span><span class="n">shape</span> <span class="o">-</span> <span class="mf">1.0</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">fails</span><span class="o">/</span><span class="n">scale</span><span class="p">)</span>
    <span class="n">xly_2</span> <span class="o">=</span> <span class="p">(</span><span class="n">gshape</span> <span class="o">-</span> <span class="mf">1.0</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">shape</span> <span class="o">-</span> <span class="mf">1.0</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">xly_1</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">xly_1</span><span class="p">))]</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">fail_like</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span> <span class="o">+</span>
                 <span class="n">xly_1</span> <span class="o">-</span> <span class="p">(</span><span class="n">fails</span><span class="o">/</span><span class="n">scale</span><span class="p">)</span><span class="o">**</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">cens_like</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">cens</span><span class="o">/</span><span class="n">scale</span><span class="p">)</span><span class="o">**</span><span class="n">shape</span>

    <span class="n">prior</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">loggamma</span><span class="p">(</span><span class="n">gshape</span><span class="p">)</span> <span class="o">+</span> <span class="n">gshape</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">gscale</span><span class="p">))</span> <span class="o">+</span>
             <span class="n">xly_2</span> <span class="o">-</span> <span class="p">(</span><span class="n">scale</span><span class="o">/</span><span class="n">gscale</span><span class="p">))</span>

    <span class="n">post</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">fail_like</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">cens_like</span><span class="p">)</span> <span class="o">+</span> <span class="n">prior</span> <span class="o">+</span> <span class="n">param</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">param</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="k">if</span> <span class="ow">not</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">post</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">post</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">neg</span><span class="p">:</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">post</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">post</span></div>


<div class="viewcode-block" id="NHPP_posterior"><a class="viewcode-back" href="../../generated/tsdst.distributions.NHPP_posterior.html#tsdst.distributions.NHPP_posterior">[docs]</a><span class="k">def</span> <span class="nf">NHPP_posterior</span><span class="p">(</span><span class="n">lparm</span><span class="p">,</span> <span class="n">tints</span><span class="p">,</span> <span class="n">tbar</span><span class="p">,</span> <span class="n">obs</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">neg</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                   <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The posterior density of the non-homogenous Poisson distribution with</span>
<span class="sd">    a power-law process. </span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    lparm : numpy array (float)</span>
<span class="sd">        log parameters eta and phi (shape and scale with a variable change).</span>
<span class="sd">    tints : numpy array (int)</span>
<span class="sd">        The sequence of time intervals (1,2,3, etc...) for the poisson counts.</span>
<span class="sd">    tbar : int</span>
<span class="sd">        time between tints (usually 1).</span>
<span class="sd">    obs : numpy array (int)</span>
<span class="sd">        The data (usually count) for the poisson process (equal to length as tints).</span>
<span class="sd">    a : float</span>
<span class="sd">        lower bound of the uniform prior on phi.</span>
<span class="sd">    b : float</span>
<span class="sd">        upper bound of the uniform prior on phi.</span>
<span class="sd">    mu : float</span>
<span class="sd">        This is a paramter that is part of the variable change on the gamma</span>
<span class="sd">        prior for the poisson likelihood.</span>
<span class="sd">    sigma : float</span>
<span class="sd">        This is a paramter that is part of the variable change on the gamma</span>
<span class="sd">        prior for the poisson likelihood.</span>
<span class="sd">    neg : bool, optional</span>
<span class="sd">        Return negative density. The default value is False.</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        Return log-density. The default value is True.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        The posterior density (height of the posterior density).</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># The Log postirior for NHPP with rate = (phi/eta)*(t/eta)**(phi-1) using</span>
    <span class="c1"># only Math no premade distributions.</span>

    <span class="c1"># Preform variable change.</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">lparm</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">*</span> <span class="n">b</span> <span class="o">+</span> <span class="n">a</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">lparm</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">lparm</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

    <span class="c1"># Extrace interval start and end times from time series.</span>
    <span class="n">int_start</span> <span class="o">=</span> <span class="n">tints</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="nb">len</span><span class="p">(</span><span class="n">tints</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">int_end</span> <span class="o">=</span> <span class="n">tints</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="nb">len</span><span class="p">(</span><span class="n">tints</span><span class="p">)]</span>

    <span class="c1"># Clculate log prior</span>
    <span class="c1"># This prior is a Gamma distribution with shape = (mu/sigma)^2,</span>
    <span class="c1"># Rate = (mu/sigma^2), a verible change of x = (t_bar/eta)^phi was made</span>
    <span class="c1"># with variable eta and phi and t_bar as constants. So the end prior is</span>
    <span class="c1"># Gamma((t_bar/eta)^phi,(mu/sigma)^2,(mu/sigma^2))*(dx/deta)*Uniform(phi,a,b)</span>
    <span class="n">lp</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">mu</span><span class="o">/</span><span class="n">sigma</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">mu</span><span class="o">/</span><span class="n">sigma</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">mu</span><span class="o">/</span><span class="p">(</span><span class="n">sigma</span><span class="o">*</span><span class="n">sigma</span><span class="p">))</span> <span class="o">+</span>
          <span class="p">(</span><span class="n">shape</span><span class="o">*</span><span class="p">(</span><span class="n">mu</span><span class="o">/</span><span class="n">sigma</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">mu</span><span class="o">/</span><span class="n">sigma</span><span class="p">))</span><span class="o">*</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">tbar</span><span class="p">)</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">scale</span><span class="p">))</span> <span class="o">-</span>
          <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="n">mu</span><span class="o">/</span><span class="p">(</span><span class="n">sigma</span><span class="o">*</span><span class="n">sigma</span><span class="p">))</span><span class="o">*</span><span class="p">((</span><span class="n">tbar</span><span class="o">/</span><span class="n">scale</span><span class="p">)</span><span class="o">**</span><span class="n">shape</span><span class="p">)</span> <span class="o">-</span>
          <span class="n">loggamma</span><span class="p">((</span><span class="n">mu</span><span class="o">/</span><span class="n">sigma</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">mu</span><span class="o">/</span><span class="n">sigma</span><span class="p">)))</span>
    <span class="n">lp_unif</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">if</span> <span class="n">a</span> <span class="o">&gt;=</span> <span class="n">b</span><span class="p">:</span>
        <span class="n">lp_unif</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    <span class="k">elif</span> <span class="n">a</span> <span class="o">&lt;=</span> <span class="n">shape</span> <span class="o">&lt;=</span> <span class="n">b</span><span class="p">:</span>
        <span class="n">lp_unif</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">b</span> <span class="o">-</span> <span class="n">a</span><span class="p">)</span>

    <span class="n">lprior</span> <span class="o">=</span> <span class="n">lp</span> <span class="o">+</span> <span class="n">lp_unif</span>

    <span class="c1"># Calulate log Liklihood</span>
    <span class="n">llik</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
            <span class="n">obs</span><span class="o">*</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(((</span><span class="n">int_end</span><span class="o">/</span><span class="n">scale</span><span class="p">)</span><span class="o">**</span><span class="n">shape</span><span class="p">)</span> <span class="o">-</span>
                        <span class="p">((</span><span class="n">int_start</span><span class="o">/</span><span class="n">scale</span><span class="p">)</span><span class="o">**</span><span class="n">shape</span><span class="p">)))</span> <span class="o">-</span>
                <span class="p">(((</span><span class="n">int_end</span><span class="o">/</span><span class="n">scale</span><span class="p">)</span><span class="o">**</span><span class="n">shape</span><span class="p">)</span> <span class="o">-</span>
                 <span class="p">((</span><span class="n">int_start</span><span class="o">/</span><span class="n">scale</span><span class="p">)</span><span class="o">**</span><span class="n">shape</span><span class="p">))</span> <span class="o">-</span> <span class="n">loggamma</span><span class="p">(</span><span class="n">obs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>

    <span class="c1"># Calulate Log Jacobian from the above variable change.</span>
    <span class="c1"># the term np.log(b-a) was removed because it&#39;s just a constant.</span>
    <span class="n">ljac</span> <span class="o">=</span> <span class="p">(</span><span class="n">lparm</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">lparm</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mf">2.0</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">lparm</span><span class="p">[</span><span class="mi">0</span><span class="p">])))</span>
    
    <span class="n">post</span> <span class="o">=</span> <span class="n">llik</span> <span class="o">+</span> <span class="n">lprior</span> <span class="o">+</span> <span class="n">ljac</span>
    
    <span class="k">if</span> <span class="ow">not</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">post</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">post</span><span class="p">)</span>
    <span class="c1"># Sum and return</span>
    <span class="k">if</span> <span class="n">neg</span><span class="p">:</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">post</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">post</span></div>
</pre></div>

    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2020 - present, Tom Werner.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.1.2.<br/>
    </p>
  </div>
</footer>
  </body>
</html>