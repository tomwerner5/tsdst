<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>tsdst.estimators &#8212; tsdst 1.0.11 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/bootstrap-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="../../_static/js/jquery-1.11.0.min.js "></script>
<script type="text/javascript" src="../../_static/js/jquery-fix.js "></script>
<script type="text/javascript" src="../../_static/bootstrap-3.3.7/js/bootstrap.min.js "></script>
<script type="text/javascript" src="../../_static/bootstrap-sphinx.js "></script>

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../../index.html">
          tsdst</a>
        <span class="navbar-text navbar-version pull-left"><b></b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../api.html">API Pages</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"></ul>
</li>
              
            
            
              
                
              
            
            
            
            
              <li class="hidden-sm"></li>
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="body col-md-12 content" role="main">
      
  <h1>Source code for tsdst.estimators</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">minimize</span>
<span class="kn">from</span> <span class="nn">scipy.special</span> <span class="kn">import</span> <span class="n">xlogy</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">BaseEstimator</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span> <span class="k">as</span> <span class="n">glm_lr</span>
<span class="c1">### keeping in case using an older version of sklearn</span>
<span class="kn">from</span> <span class="nn">statsmodels.genmod.generalized_linear_model</span> <span class="kn">import</span> <span class="n">GLM</span> <span class="k">as</span> <span class="n">glm_pois</span>
<span class="kn">from</span> <span class="nn">statsmodels.genmod.families.family</span> <span class="kn">import</span> <span class="n">Poisson</span>
<span class="c1">###</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model._base</span> <span class="kn">import</span> <span class="n">LinearClassifierMixin</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">get_scorer</span>
<span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">check_array</span>
<span class="kn">from</span> <span class="nn">sklearn.utils.extmath</span> <span class="kn">import</span> <span class="n">softmax</span>
<span class="kn">from</span> <span class="nn">sklearn.utils.validation</span> <span class="kn">import</span> <span class="n">check_is_fitted</span><span class="p">,</span> <span class="n">_check_sample_weight</span>
<span class="kn">from</span> <span class="nn">statsmodels.tools</span> <span class="kn">import</span> <span class="n">add_constant</span>
<span class="kn">from</span> <span class="nn">timeit</span> <span class="kn">import</span> <span class="n">default_timer</span> <span class="k">as</span> <span class="n">dt</span>

<span class="kn">from</span> <span class="nn">.distributions</span> <span class="kn">import</span> <span class="p">(</span><span class="n">ap_logreg_lasso</span><span class="p">,</span>
                                 <span class="n">posterior_logreg_lasso</span><span class="p">,</span>
                                 <span class="n">likelihood_bernoulli</span><span class="p">,</span>
                                 <span class="n">posterior_poisson_lasso</span><span class="p">,</span>
                                 <span class="n">ap_poisson_lasso</span><span class="p">,</span>
                                 <span class="n">posterior_poisson_lasso_od</span><span class="p">,</span>
                                 <span class="n">ap_poisson_lasso_od</span><span class="p">,</span>
                                 <span class="n">weibull_regression_post</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">.mcmc</span> <span class="kn">import</span> <span class="n">adaptive_mcmc</span><span class="p">,</span> <span class="n">rwm_with_lap</span><span class="p">,</span> <span class="n">rwm</span><span class="p">,</span> <span class="n">applyMCMC</span>
<span class="kn">from</span> <span class="nn">.tmath</span> <span class="kn">import</span> <span class="n">mode_histogram</span><span class="p">,</span> <span class="n">mode_kde</span>
<span class="kn">from</span> <span class="nn">.utils</span> <span class="kn">import</span> <span class="n">print_time</span>


<div class="viewcode-block" id="BayesLogRegClassifier"><a class="viewcode-back" href="../../generated/tsdst.estimators.BayesLogRegClassifier.html#tsdst.estimators.BayesLogRegClassifier">[docs]</a><span class="k">class</span> <span class="nc">BayesLogRegClassifier</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">LinearClassifierMixin</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A Logistic Regression Classifier that uses MCMC to evaluate the parameters.</span>
<span class="sd">    This objects inherits from sklearn\&#39;s BaseEstimator and</span>
<span class="sd">    LinearClassifierMixin.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="BayesLogRegClassifier.__init__"><a class="viewcode-back" href="../../generated/tsdst.estimators.BayesLogRegClassifier.__init__.html#tsdst.estimators.BayesLogRegClassifier.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">niter</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">algo</span><span class="o">=</span><span class="s1">&#39;rosenthal&#39;</span><span class="p">,</span>
                 <span class="n">algo_options</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">retry_sd</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span> <span class="n">retry_max_tries</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                 <span class="n">initialize_weights</span><span class="o">=</span><span class="s1">&#39;sklearn&#39;</span><span class="p">,</span> <span class="n">param_summary</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span>
                 <span class="n">has_constant</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">over_dispersion</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">scorer</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># TODO: Implement random_state for reproduceability</span>
        <span class="sd">&quot;&quot;&quot;The constructor for the BayesLogRegClassifier</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        C : float, optional</span>
<span class="sd">            The value for the inverse L1 penalty, or, the inverse</span>
<span class="sd">            regularization strength. If None, the MCMC process</span>
<span class="sd">            looks for the optimal penalty. The default is None.</span>
<span class="sd">            </span>
<span class="sd">            This value gets converted into the scale parameter for a laplace</span>
<span class="sd">            distribution (scale = 2*C).</span>
<span class="sd">        start : numpy array (float), optional</span>
<span class="sd">            The starting values for the MCMC. If None, the MLE estimate is used</span>
<span class="sd">            (solved with sklearn). The default is None.</span>
<span class="sd">        niter : int, optional</span>
<span class="sd">            The number of MCMC samples to draw. The default is 10000.</span>
<span class="sd">        algo : str, optional</span>
<span class="sd">            The MCMC (Metropolis) algorithm to use. The default is &#39;rosenthal&#39;,</span>
<span class="sd">            which is a method that tunes the covariance matrix after each</span>
<span class="sd">            iteration. Other options include &#39;rwm&#39;, which is a simple random</span>
<span class="sd">            metropolis walk with a fixed covariance matrix, and &#39;lap&#39; which is</span>
<span class="sd">            another adaptive method that tunes the covariance matrix every K</span>
<span class="sd">            iterations.</span>
<span class="sd">        algo_options : dict, optional</span>
<span class="sd">            The options to be passed to the MCMC algorithm. Include as a</span>
<span class="sd">            dictionary. The default is None.</span>
<span class="sd">        retry_sd : float, optional</span>
<span class="sd">            The MCMC alorithms use a Cholesky decomposition on the covariance</span>
<span class="sd">            matrix. In case the decomposition fails, the algorithms will </span>
<span class="sd">            attempt to jitter the covaraince matrix to help it be positive </span>
<span class="sd">            definite. This value determines the strength of the jittering and</span>
<span class="sd">            is drawn directly from a normal distribution with zero mean and</span>
<span class="sd">            retry_sd standard deviation. The default is 0.02.</span>
<span class="sd">        retry_max_tries : int, optional</span>
<span class="sd">            Number of attempts to correct the cholesky decomposition if it</span>
<span class="sd">            fails. The default is 100.</span>
<span class="sd">        initialize_weights : str, optional</span>
<span class="sd">            Determines the method of initializing the starting model parameter</span>
<span class="sd">            values (if start is None). Options are &#39;sklearn&#39;, &#39;ones&#39;, &#39;random&#39;,</span>
<span class="sd">            or &#39;zeros&#39;. The default is &#39;sklearn&#39;.</span>
<span class="sd">        param_summary : str, optional</span>
<span class="sd">            The method used in making the final parameter summaries. Options </span>
<span class="sd">            are &#39;mean&#39;, &#39;median&#39;, &#39;mode_kde&#39;, &#39;mode_histogram&#39;, or</span>
<span class="sd">            &#39;final_sample&#39;. The default is &#39;mean&#39;.</span>
<span class="sd">        has_constant : bool, optional</span>
<span class="sd">            Whether or not the data provided already has a column of ones</span>
<span class="sd">            as the first column in the dataset for the intercept of the model.</span>
<span class="sd">            If not, one is created. The default is False.</span>
<span class="sd">        verbose : bool, optional</span>
<span class="sd">            If True, a progress bar, along with timestamps, is provided.</span>
<span class="sd">            The default is True.</span>
<span class="sd">        over_dispersion : bool, optional</span>
<span class="sd">            Whether or not to account for overdispersion in the model.</span>
<span class="sd">            The default is False.</span>
<span class="sd">        scorer : function or str</span>
<span class="sd">            The function or string to use for the default scoring method.</span>
<span class="sd">            Otherwise, pass None for accuracy. The default is None.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        None.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">C</span> <span class="o">=</span> <span class="n">C</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">start</span> <span class="o">=</span> <span class="n">start</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">niter</span> <span class="o">=</span> <span class="n">niter</span>
        <span class="k">if</span> <span class="n">algo</span> <span class="o">==</span> <span class="s1">&#39;rosenthal&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">algo</span> <span class="o">=</span> <span class="n">adaptive_mcmc</span>
        <span class="k">elif</span> <span class="n">algo</span> <span class="o">==</span> <span class="s1">&#39;lap&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">algo</span> <span class="o">=</span> <span class="n">rwm_with_lap</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">algo</span> <span class="o">=</span> <span class="n">rwm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">algo_options</span> <span class="o">=</span> <span class="n">algo_options</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">param_summary</span> <span class="o">=</span> <span class="n">param_summary</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initialize_weights</span> <span class="o">=</span> <span class="n">initialize_weights</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">has_constant</span> <span class="o">=</span> <span class="n">has_constant</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">retry_sd</span> <span class="o">=</span> <span class="n">retry_sd</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">retry_max_tries</span> <span class="o">=</span> <span class="n">retry_max_tries</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scorer</span> <span class="o">=</span> <span class="n">scorer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">over_dispersion</span> <span class="o">=</span> <span class="n">over_dispersion</span>
        <span class="k">if</span> <span class="n">C</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># TODO: Implement over-dispersion</span>
            <span class="c1">#if over_dispersion:</span>
            <span class="c1">#    self.lpost = ap_logreg_lasso_od</span>
            <span class="c1">#    self.extra_params = 2</span>
            <span class="c1">#else:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lpost</span> <span class="o">=</span> <span class="n">ap_logreg_lasso</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">extra_params</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1">#if over_dispersion:</span>
            <span class="c1">#    self.lpost = posterior_logreg_lasso_od</span>
            <span class="c1">#    self.extra_params = 1</span>
            <span class="c1">#else:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lpost</span> <span class="o">=</span> <span class="n">posterior_logreg_lasso</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">extra_params</span> <span class="o">=</span> <span class="mi">0</span></div>
            
    <span class="k">def</span> <span class="nf">_create_coefs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mcmc_params</span><span class="p">,</span> <span class="n">param_summary</span><span class="p">,</span> <span class="n">extra_params</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Creates Coefficients for MCMC model by aggregating the MCMC samples,</span>
<span class="sd">        using mean, median, mode, or last sampled value.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        mcmc_params : numpy array (float)</span>
<span class="sd">            MCMC chain, one column for each parameter.</span>
<span class="sd">        param_summary : str</span>
<span class="sd">            The method of aggregation (either mean, median, mode_kde,</span>
<span class="sd">            mode_histogram, or last_value.</span>
<span class="sd">        extra_params : int</span>
<span class="sd">            The number of extra params used in the MCMC process (for example,</span>
<span class="sd">        parameters for priors or overdispersion).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        coefs : numpy array (float)</span>
<span class="sd">            The coefficients of the model (aggregated from the MCMC chain).</span>
<span class="sd">        intercept : float</span>
<span class="sd">            The intercept of the model (aggregated from the MCMC chain).</span>
<span class="sd">        extra_parm : numpy array (float)</span>
<span class="sd">            Any extra parameters that were solved with the model (aggregated</span>
<span class="sd">            from the MCMC chain).</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">sum_parms</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">param_summary</span> <span class="o">==</span> <span class="s1">&#39;mean&#39;</span><span class="p">:</span>
            <span class="n">sum_parms</span> <span class="o">=</span> <span class="n">mcmc_params</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">param_summary</span> <span class="o">==</span> <span class="s1">&#39;median&#39;</span><span class="p">:</span>
            <span class="n">sum_parms</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">mcmc_params</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">param_summary</span> <span class="o">==</span> <span class="s1">&#39;mode_histogram&#39;</span><span class="p">:</span>
            <span class="n">sum_parms</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">mode_histogram</span><span class="p">(</span><span class="n">mcmc_params</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">mcmc_params</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])])</span>
        <span class="k">elif</span> <span class="n">param_summary</span> <span class="o">==</span> <span class="s1">&#39;mode_kde&#39;</span><span class="p">:</span>
            <span class="n">sum_parms</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">mode_kde</span><span class="p">(</span><span class="n">mcmc_params</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">mcmc_params</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">sum_parms</span> <span class="o">=</span> <span class="n">mcmc_params</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
        
        <span class="k">if</span> <span class="n">extra_params</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">extra_parm</span> <span class="o">=</span> <span class="n">sum_parms</span><span class="p">[</span><span class="o">-</span><span class="n">extra_params</span><span class="p">:]</span>
            <span class="n">coefs</span> <span class="o">=</span> <span class="n">sum_parms</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="n">extra_params</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">extra_parm</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">coefs</span> <span class="o">=</span> <span class="n">sum_parms</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">intercept</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">sum_parms</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        
        <span class="k">return</span> <span class="n">coefs</span><span class="p">,</span> <span class="n">intercept</span><span class="p">,</span> <span class="n">extra_parm</span>
        
<div class="viewcode-block" id="BayesLogRegClassifier.adjust_params_"><a class="viewcode-back" href="../../generated/tsdst.estimators.BayesLogRegClassifier.adjust_params_.html#tsdst.estimators.BayesLogRegClassifier.adjust_params_">[docs]</a>    <span class="k">def</span> <span class="nf">adjust_params_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_param_summary</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;This method is intended to update the aggregated parameters with a new</span>
<span class="sd">        summary as defined in new_param_summary. For example, if someone wanted</span>
<span class="sd">        to switch from `coef_` representing the mean to `coef_` representing</span>
<span class="sd">        the median, they could use this function to do so.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        new_param_summary : str</span>
<span class="sd">            The method of aggregating the MCMC chain parameters (either mean,</span>
<span class="sd">            median, mode_kde, mode_histogram, or last_value).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self</span>
<span class="sd">            Updates the `coef_`, `intercept_`, and `extra_params_sum_` attributes.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">intercept_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">extra_params_sum_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_coefs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mcmc_params</span><span class="p">,</span> <span class="n">new_param_summary</span><span class="p">,</span>
                                                                                 <span class="bp">self</span><span class="o">.</span><span class="n">extra_params</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>
    
<div class="viewcode-block" id="BayesLogRegClassifier.fit"><a class="viewcode-back" href="../../generated/tsdst.estimators.BayesLogRegClassifier.fit.html#tsdst.estimators.BayesLogRegClassifier.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Fit the model</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : numpy array</span>
<span class="sd">            The feature (or design) matrix.</span>
<span class="sd">        y : numpy array</span>
<span class="sd">            The response variable.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self</span>
<span class="sd">            Updates internal attributes, such as `coef_` and `intercept_`.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">t0</span> <span class="o">=</span> <span class="n">dt</span><span class="p">()</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">force_all_finite</span><span class="o">=</span><span class="s1">&#39;allow-nan&#39;</span><span class="p">,</span> <span class="n">estimator</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_constant</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">add_constant</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">prepend</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>       
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">start</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">pass</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="n">print_time</span><span class="p">(</span><span class="s2">&quot;Initializing Coefficients...&quot;</span><span class="p">,</span> <span class="n">t0</span><span class="p">,</span> <span class="n">dt</span><span class="p">(),</span> <span class="n">backsn</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">initialize_weights</span> <span class="o">==</span> <span class="s1">&#39;sklearn&#39;</span><span class="p">:</span>
                <span class="n">C</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">C</span>
                <span class="k">if</span> <span class="n">C</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">C</span> <span class="o">=</span> <span class="mi">1</span>
                <span class="n">mod</span> <span class="o">=</span> <span class="n">glm_lr</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="n">C</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;liblinear&#39;</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span> <span class="n">fit_intercept</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">start</span> <span class="o">=</span> <span class="n">mod</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">extra_params</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">start</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">start</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">extra_params</span><span class="p">)))</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">initialize_weights</span> <span class="o">==</span> <span class="s1">&#39;ones&#39;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">start</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">extra_params</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">initialize_weights</span> <span class="o">==</span> <span class="s1">&#39;random&#39;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">start</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">extra_params</span><span class="p">,</span> <span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">start</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">extra_params</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="n">print_time</span><span class="p">(</span><span class="s2">&quot;Beginning MCMC...&quot;</span><span class="p">,</span> <span class="n">t0</span><span class="p">,</span> <span class="n">dt</span><span class="p">(),</span> <span class="n">backsn</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        
        <span class="n">postArgs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">X</span><span class="p">,</span>
            <span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">y</span><span class="p">,</span>
            <span class="s1">&#39;l_scale&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">C</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">C</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">2</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">C</span>
        <span class="p">}</span>
        
        <span class="n">algo_res</span> <span class="o">=</span> <span class="n">applyMCMC</span><span class="p">(</span><span class="n">st</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">start</span><span class="p">,</span> <span class="n">ni</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">niter</span><span class="p">,</span> <span class="n">lp</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lpost</span><span class="p">,</span>
                             <span class="n">algo</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">algo</span><span class="p">,</span> <span class="n">postArgs</span><span class="o">=</span><span class="n">postArgs</span><span class="p">,</span>
                             <span class="n">algoOpts</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">algo_options</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">retry_sd</span><span class="p">,</span>
                             <span class="n">max_tries</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">retry_max_tries</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">mcmc_params</span> <span class="o">=</span> <span class="n">algo_res</span><span class="p">[</span><span class="s1">&#39;parameters&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prev_vals</span> <span class="o">=</span> <span class="n">algo_res</span><span class="p">[</span><span class="s1">&#39;prev_vals&#39;</span><span class="p">]</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">intercept_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">extra_params_sum_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_coefs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mcmc_params</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">param_summary</span><span class="p">,</span>
                                                                                 <span class="bp">self</span><span class="o">.</span><span class="n">extra_params</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">niter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classes_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">over_dispersion</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dispersion_estimation_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extra_params_sum_</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dispersion_estimation_</span> <span class="o">=</span> <span class="kc">None</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="n">print_time</span><span class="p">(</span><span class="s2">&quot;Finished MCMC. Stored Coefficients...&quot;</span><span class="p">,</span> <span class="n">t0</span><span class="p">,</span> <span class="n">dt</span><span class="p">(),</span> <span class="n">backsn</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            
        <span class="k">return</span> <span class="bp">self</span></div>
    
<div class="viewcode-block" id="BayesLogRegClassifier.predict"><a class="viewcode-back" href="../../generated/tsdst.estimators.BayesLogRegClassifier.predict.html#tsdst.estimators.BayesLogRegClassifier.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;coef_&#39;</span><span class="p">)</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="c1"># note: decision_function returns X.dot(Betas). This code, modified from sklearn,</span>
        <span class="c1"># computes the decision based on the sign of the log odds ratio (X.dot(betas) == log(p/(1-p))).</span>
        <span class="c1"># When p &lt;= 0.5, decision is 0, when p &gt; 0.5, decision is 1 (threshold of 0.5 is the default for sklearn). </span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">scores</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="p">(</span><span class="n">scores</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># returning the value in this way allows for someone to define their own classes,</span>
        <span class="c1"># for example, -1, 1 instead of 0, 1</span>
        <span class="c1"># Note: this is used in sklearn, but this code is not be robust enough for that,</span>
        <span class="c1"># so you need to define your classes as 0, 1</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">classes_</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span></div>
    
<div class="viewcode-block" id="BayesLogRegClassifier.predict_proba"><a class="viewcode-back" href="../../generated/tsdst.estimators.BayesLogRegClassifier.predict_proba.html#tsdst.estimators.BayesLogRegClassifier.predict_proba">[docs]</a>    <span class="k">def</span> <span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Generate predicted probability.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : numpy array</span>
<span class="sd">            Feature (or design) matrix.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        numpy array (float)</span>
<span class="sd">            The predicted probabilities.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;coef_&#39;</span><span class="p">)</span>
        
        <span class="n">decision</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">decision_2d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="o">-</span><span class="n">decision</span><span class="p">,</span> <span class="n">decision</span><span class="p">]</span>
        
        <span class="k">return</span> <span class="n">softmax</span><span class="p">(</span><span class="n">decision_2d</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></div>
    
<div class="viewcode-block" id="BayesLogRegClassifier.predict_log_proba"><a class="viewcode-back" href="../../generated/tsdst.estimators.BayesLogRegClassifier.predict_log_proba.html#tsdst.estimators.BayesLogRegClassifier.predict_log_proba">[docs]</a>    <span class="k">def</span> <span class="nf">predict_log_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Generate predicted log probability.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : numpy array</span>
<span class="sd">            Feature (or design) matrix.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        numpy array (float)</span>
<span class="sd">            The predicted log probabilities.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">))</span></div>
    
<div class="viewcode-block" id="BayesLogRegClassifier.score"><a class="viewcode-back" href="../../generated/tsdst.estimators.BayesLogRegClassifier.score.html#tsdst.estimators.BayesLogRegClassifier.score">[docs]</a>    <span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Scores the model using the scoring method passed, or, the default</span>
<span class="sd">        scorer. In this case, the default scorer is accuracy.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : numpy array or pandas dataframe</span>
<span class="sd">            The design or feature matrix.</span>
<span class="sd">        y : numpy array or pandas series</span>
<span class="sd">            The target or response variable.</span>
<span class="sd">        sample_weight : numpy array, optional</span>
<span class="sd">            An array containing the weights for each sample.</span>
<span class="sd">            The default is None.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        score</span>
<span class="sd">            The result of the scoring function.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">scorer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scorer</span> <span class="ow">or</span> <span class="s1">&#39;accuracy&#39;</span>
        <span class="n">scorer</span> <span class="o">=</span> <span class="n">get_scorer</span><span class="p">(</span><span class="n">scorer</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">scorer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="BayesPoissonRegressor"><a class="viewcode-back" href="../../generated/tsdst.estimators.BayesPoissonRegressor.html#tsdst.estimators.BayesPoissonRegressor">[docs]</a><span class="k">class</span> <span class="nc">BayesPoissonRegressor</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">LinearClassifierMixin</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A Poisson Regressor that uses MCMC to evaluate the parameters.</span>
<span class="sd">    This objects inherits from sklearn\&#39;s BaseEstimator and</span>
<span class="sd">    LinearClassifierMixin.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="BayesPoissonRegressor.__init__"><a class="viewcode-back" href="../../generated/tsdst.estimators.BayesPoissonRegressor.__init__.html#tsdst.estimators.BayesPoissonRegressor.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">niter</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">algo</span><span class="o">=</span><span class="s1">&#39;rosenthal&#39;</span><span class="p">,</span>
                 <span class="n">algo_options</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">retry_sd</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span> <span class="n">retry_max_tries</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                 <span class="n">initialize_weights</span><span class="o">=</span><span class="s1">&#39;sklearn&#39;</span><span class="p">,</span> <span class="n">param_summary</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span>
                 <span class="n">has_constant</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">over_dispersion</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">scorer</span><span class="o">=</span><span class="s1">&#39;D2&#39;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The constructor for the BayesPoissonClassifier</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        C : float, optional</span>
<span class="sd">            The value for the inverse L1 penalty, or, the inverse</span>
<span class="sd">            regularization strength. If None, the MCMC process</span>
<span class="sd">            looks for the optimal penalty. The default is None.</span>
<span class="sd">            </span>
<span class="sd">            This value is gets converted into the scale parameter for a laplace</span>
<span class="sd">            distribution (scale = 2*C).</span>
<span class="sd">        start : numpy array (float), optional</span>
<span class="sd">            The starting values for the MCMC. If None, the MLE estimate is used</span>
<span class="sd">            (solved with sklearn). The default is None.</span>
<span class="sd">        niter : int, optional</span>
<span class="sd">            The number of MCMC samples to draw. The default is 10000.</span>
<span class="sd">        algo : str, optional</span>
<span class="sd">            The MCMC (Metropolis) algorithm to use. The default is &#39;rosenthal&#39;, which is </span>
<span class="sd">            a method that tunes the covariance matrix after each iteration.</span>
<span class="sd">            Other options include &#39;rwm&#39;, which is a simple random metropolis</span>
<span class="sd">            walk with a fixed covariance matrix, and &#39;lap&#39; which is another </span>
<span class="sd">            adaptive method that tunes the covariance matrix every K</span>
<span class="sd">            iterations.</span>
<span class="sd">        algo_options : dict, optional</span>
<span class="sd">            The options to be passed to the MCMC algorithm. Include as a</span>
<span class="sd">            dictionary. The default is None.</span>
<span class="sd">        retry_sd : float, optional</span>
<span class="sd">            The MCMC alorithms use a Cholesky decomposition on the covariance</span>
<span class="sd">            matrix. In case the decomposition fails, the algorithms will </span>
<span class="sd">            attempt to jitter the covaraince matrix to help it be positive </span>
<span class="sd">            definite. This value determines the strength of the jittering and</span>
<span class="sd">            is drawn directly from a normal distribution with zero mean and</span>
<span class="sd">            retry_sd standard deviation. The default is 0.02.</span>
<span class="sd">        retry_max_tries : int, optional</span>
<span class="sd">            Number of attempts to correct the cholesky decomposition if it</span>
<span class="sd">            fails. The default is 100.</span>
<span class="sd">        initialize_weights : str, optional</span>
<span class="sd">            Determines the method of initializing the starting model parameter</span>
<span class="sd">            values (if start is None). Options are &#39;sklearn&#39;, &#39;ones&#39;, &#39;random&#39;,</span>
<span class="sd">            or &#39;zeros&#39;. The default is &#39;sklearn&#39;.</span>
<span class="sd">        param_summary : str, optional</span>
<span class="sd">            The method used in making the final parameter summaries. Options </span>
<span class="sd">            are &#39;mean&#39;, &#39;median&#39;, &#39;mode_kde&#39;, &#39;mode_histogram&#39;, or</span>
<span class="sd">            &#39;final_sample&#39;. The default is &#39;mean&#39;.</span>
<span class="sd">        has_constant : bool, optional</span>
<span class="sd">            Whether or not the data provided already has a column of ones</span>
<span class="sd">            as the first column in the dataset for the intercept of the model.</span>
<span class="sd">            If not, one is created. The default is False.</span>
<span class="sd">        verbose : bool, optional</span>
<span class="sd">            If True, a progress bar, along with timestamps, is provided.</span>
<span class="sd">            The default is True.</span>
<span class="sd">        over_dispersion : bool, optional</span>
<span class="sd">            Whether or not to account for overdispersion in the model.</span>
<span class="sd">            The default is False.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        None.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">C</span> <span class="o">=</span> <span class="n">C</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">start</span> <span class="o">=</span> <span class="n">start</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">niter</span> <span class="o">=</span> <span class="n">niter</span>
        <span class="k">if</span> <span class="n">algo</span> <span class="o">==</span> <span class="s1">&#39;rosenthal&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">algo</span> <span class="o">=</span> <span class="n">adaptive_mcmc</span>
        <span class="k">elif</span> <span class="n">algo</span> <span class="o">==</span> <span class="s1">&#39;lap&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">algo</span> <span class="o">=</span> <span class="n">rwm_with_lap</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">algo</span> <span class="o">=</span> <span class="n">rwm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">algo_options</span> <span class="o">=</span> <span class="n">algo_options</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">param_summary</span> <span class="o">=</span> <span class="n">param_summary</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initialize_weights</span> <span class="o">=</span> <span class="n">initialize_weights</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">has_constant</span> <span class="o">=</span> <span class="n">has_constant</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">retry_sd</span> <span class="o">=</span> <span class="n">retry_sd</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">retry_max_tries</span> <span class="o">=</span> <span class="n">retry_max_tries</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">over_dispersion</span> <span class="o">=</span> <span class="n">over_dispersion</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scorer</span> <span class="o">=</span> <span class="n">scorer</span>
        <span class="k">if</span> <span class="n">C</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">over_dispersion</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">lpost</span> <span class="o">=</span> <span class="n">ap_poisson_lasso_od</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">extra_params</span> <span class="o">=</span> <span class="mi">2</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">lpost</span> <span class="o">=</span> <span class="n">ap_poisson_lasso</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">extra_params</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">over_dispersion</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;using OD&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">lpost</span> <span class="o">=</span> <span class="n">posterior_poisson_lasso_od</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">extra_params</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">lpost</span> <span class="o">=</span> <span class="n">posterior_poisson_lasso</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">extra_params</span> <span class="o">=</span> <span class="mi">0</span></div>
    
    <span class="k">def</span> <span class="nf">_deviance_dispersion_update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">_check_sample_weight</span><span class="p">(</span><span class="n">sample_weight</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">y_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>
        <span class="n">deviance_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">weights</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">xlogy</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y</span><span class="o">/</span><span class="n">y_pred</span><span class="p">)</span> <span class="o">-</span> <span class="n">y</span> <span class="o">+</span> <span class="n">y_pred</span><span class="p">)))</span>
        <span class="n">null_deviance_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">weights</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">xlogy</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y</span><span class="o">/</span><span class="n">y_mean</span><span class="p">)</span> <span class="o">-</span> <span class="n">y</span> <span class="o">+</span> <span class="n">y_mean</span><span class="p">)))</span>
        <span class="c1"># pearson residual:  (raw residual)/(variance function)</span>
        <span class="n">pearson_residuals_</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">)</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
        <span class="n">pearson_chi2_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">pearson_residuals_</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">model_d2_</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">deviance_</span><span class="o">/</span><span class="n">null_deviance_</span>
        <span class="c1"># degrees of freedom of the model (all params (including intercept) minus 1)</span>
        <span class="n">df_model_</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="c1"># degrees of freedom of residuals ((n_obs - 1) - (nparms - 1)), or</span>
        <span class="n">df_residuals_</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="c1"># total degrees of freedom</span>
        <span class="n">df_total_</span> <span class="o">=</span> <span class="n">df_residuals_</span> <span class="o">+</span> <span class="n">df_model_</span>
        <span class="c1"># method of moments estimator for dispersion scale</span>
        <span class="n">dispersion_scale_</span> <span class="o">=</span> <span class="n">pearson_chi2_</span><span class="o">/</span><span class="n">df_residuals_</span>
        <span class="n">dispersion_scale_sqrt_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">dispersion_scale_</span><span class="p">)</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;deviance_&#39;</span><span class="p">:</span> <span class="n">deviance_</span><span class="p">,</span>
                   <span class="s1">&#39;null_deviance_&#39;</span><span class="p">:</span> <span class="n">null_deviance_</span><span class="p">,</span>
                   <span class="s1">&#39;pearson_residuals_&#39;</span><span class="p">:</span> <span class="n">pearson_residuals_</span><span class="p">,</span>
                   <span class="s1">&#39;pearson_chi2_&#39;</span><span class="p">:</span> <span class="n">pearson_chi2_</span><span class="p">,</span>
                   <span class="s1">&#39;model_d2_&#39;</span><span class="p">:</span> <span class="n">model_d2_</span><span class="p">,</span>
                   <span class="s1">&#39;df_model_&#39;</span><span class="p">:</span> <span class="n">df_model_</span><span class="p">,</span>
                   <span class="s1">&#39;df_residuals_&#39;</span><span class="p">:</span> <span class="n">df_residuals_</span><span class="p">,</span>
                   <span class="s1">&#39;df_total_&#39;</span><span class="p">:</span> <span class="n">df_total_</span><span class="p">,</span>
                   <span class="s1">&#39;dispersion_scale_&#39;</span><span class="p">:</span> <span class="n">dispersion_scale_</span><span class="p">,</span>
                   <span class="s1">&#39;dispersion_scale_sqrt_&#39;</span><span class="p">:</span> <span class="n">dispersion_scale_sqrt_</span><span class="p">}</span>
        <span class="k">return</span> <span class="n">results</span>
        
    <span class="k">def</span> <span class="nf">_create_coefs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mcmc_params</span><span class="p">,</span> <span class="n">param_summary</span><span class="p">,</span> <span class="n">extra_params</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Creates Coefficients for MCMC model by aggregating the MCMC samples,</span>
<span class="sd">        using mean, median, mode, or last sampled value.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        mcmc_params : numpy array (float)</span>
<span class="sd">            MCMC chain, one column for each parameter.</span>
<span class="sd">        param_summary : str</span>
<span class="sd">            The method of aggregation (either mean, median, mode_kde,</span>
<span class="sd">            mode_histogram, or last_value.</span>
<span class="sd">        extra_params : int</span>
<span class="sd">            The number of extra params used in the MCMC process (for example,</span>
<span class="sd">        parameters for priors or overdispersion).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        coefs : numpy array (float)</span>
<span class="sd">            The coefficients of the model (aggregated from the MCMC chain).</span>
<span class="sd">        intercept : float</span>
<span class="sd">            The intercept of the model (aggregated from the MCMC chain).</span>
<span class="sd">        extra_parm : numpy array (float)</span>
<span class="sd">            Any extra parameters that were solved with the model (aggregated</span>
<span class="sd">            from the MCMC chain).</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">sum_parms</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">param_summary</span> <span class="o">==</span> <span class="s1">&#39;mean&#39;</span><span class="p">:</span>
            <span class="n">sum_parms</span> <span class="o">=</span> <span class="n">mcmc_params</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">param_summary</span> <span class="o">==</span> <span class="s1">&#39;median&#39;</span><span class="p">:</span>
            <span class="n">sum_parms</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">mcmc_params</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">param_summary</span> <span class="o">==</span> <span class="s1">&#39;mode_histogram&#39;</span><span class="p">:</span>
            <span class="n">sum_parms</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">mode_histogram</span><span class="p">(</span><span class="n">mcmc_params</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">mcmc_params</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])])</span>
        <span class="k">elif</span> <span class="n">param_summary</span> <span class="o">==</span> <span class="s1">&#39;mode_kde&#39;</span><span class="p">:</span>
            <span class="n">sum_parms</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">mode_kde</span><span class="p">(</span><span class="n">mcmc_params</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">mcmc_params</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">sum_parms</span> <span class="o">=</span> <span class="n">mcmc_params</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
        
        <span class="k">if</span> <span class="n">extra_params</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">extra_parm</span> <span class="o">=</span> <span class="n">sum_parms</span><span class="p">[</span><span class="o">-</span><span class="n">extra_params</span><span class="p">:]</span>
            <span class="n">coefs</span> <span class="o">=</span> <span class="n">sum_parms</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="n">extra_params</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">extra_parm</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">coefs</span> <span class="o">=</span> <span class="n">sum_parms</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">)</span>
        <span class="n">intercept</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">sum_parms</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        
        <span class="k">return</span> <span class="n">coefs</span><span class="p">,</span> <span class="n">intercept</span><span class="p">,</span> <span class="n">extra_parm</span>
        
<div class="viewcode-block" id="BayesPoissonRegressor.adjust_params_"><a class="viewcode-back" href="../../generated/tsdst.estimators.BayesPoissonRegressor.adjust_params_.html#tsdst.estimators.BayesPoissonRegressor.adjust_params_">[docs]</a>    <span class="k">def</span> <span class="nf">adjust_params_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_param_summary</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;This method is intended to update the aggregated parameters with a new</span>
<span class="sd">        summary as defined in new_param_summary. For example, if someone wanted</span>
<span class="sd">        to switch from `coef_` representing the mean to `coef_` representing</span>
<span class="sd">        the median, they could use this function to do so.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        new_param_summary : str</span>
<span class="sd">            The method of aggregating the MCMC chain parameters (either mean,</span>
<span class="sd">            median, mode_kde, mode_histogram, or last_value).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self</span>
<span class="sd">            Updates the `coef_`, `intercept_`, and `extra_params_sum_` attributes.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">intercept_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">extra_params_sum_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_coefs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mcmc_params</span><span class="p">,</span> <span class="n">new_param_summary</span><span class="p">,</span>
                                                                                 <span class="bp">self</span><span class="o">.</span><span class="n">extra_params</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="bp">self</span></div>
    
<div class="viewcode-block" id="BayesPoissonRegressor.fit"><a class="viewcode-back" href="../../generated/tsdst.estimators.BayesPoissonRegressor.fit.html#tsdst.estimators.BayesPoissonRegressor.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Fit the model</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : numpy array</span>
<span class="sd">            The feature (or design) matrix.</span>
<span class="sd">        y : numpy array</span>
<span class="sd">            The response variable.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self</span>
<span class="sd">            Updates internal attributes, such as `coef_` and `intercept_`.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">t0</span> <span class="o">=</span> <span class="n">dt</span><span class="p">()</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">force_all_finite</span><span class="o">=</span><span class="s1">&#39;allow-nan&#39;</span><span class="p">,</span> <span class="n">estimator</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_constant</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">add_constant</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">prepend</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>       
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">start</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">pass</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="n">print_time</span><span class="p">(</span><span class="s2">&quot;Initializing Coefficients...&quot;</span><span class="p">,</span> <span class="n">t0</span><span class="p">,</span> <span class="n">dt</span><span class="p">(),</span> <span class="n">backsn</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">initialize_weights</span> <span class="o">==</span> <span class="s1">&#39;sklearn&#39;</span><span class="p">:</span>
                <span class="n">C</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">C</span>
                <span class="k">if</span> <span class="n">C</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">C</span> <span class="o">=</span> <span class="mi">1</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">PoissonRegressor</span> <span class="k">as</span> <span class="n">glm_pois_sk</span>
                    <span class="n">mod</span> <span class="o">=</span> <span class="n">glm_pois_sk</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="n">C</span><span class="p">,</span> <span class="n">fit_intercept</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">start</span> <span class="o">=</span> <span class="n">mod</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">)</span>
                <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Older sklearn, no PoissonRegressor. Using statsmodels instead&#39;</span><span class="p">)</span>
                    <span class="n">mod</span> <span class="o">=</span> <span class="n">glm_pois</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="n">Poisson</span><span class="p">())</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">start</span> <span class="o">=</span> <span class="n">mod</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">extra_params</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">start</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">start</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">extra_params</span><span class="p">)))</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">initialize_weights</span> <span class="o">==</span> <span class="s1">&#39;ones&#39;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">start</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">extra_params</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">initialize_weights</span> <span class="o">==</span> <span class="s1">&#39;random&#39;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">start</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">extra_params</span><span class="p">,</span> <span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">start</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">extra_params</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="n">print_time</span><span class="p">(</span><span class="s2">&quot;Beginning MCMC...&quot;</span><span class="p">,</span> <span class="n">t0</span><span class="p">,</span> <span class="n">dt</span><span class="p">(),</span> <span class="n">backsn</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        
        <span class="n">postArgs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">X</span><span class="p">,</span>
            <span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">y</span><span class="p">,</span>
            <span class="s1">&#39;l_scale&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">C</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">C</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">2</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">C</span>
        <span class="p">}</span>
        
        <span class="n">algo_res</span> <span class="o">=</span> <span class="n">applyMCMC</span><span class="p">(</span><span class="n">st</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">start</span><span class="p">,</span> <span class="n">ni</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">niter</span><span class="p">,</span> <span class="n">lp</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lpost</span><span class="p">,</span>
                             <span class="n">algo</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">algo</span><span class="p">,</span> <span class="n">postArgs</span><span class="o">=</span><span class="n">postArgs</span><span class="p">,</span>
                             <span class="n">algoOpts</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">algo_options</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">retry_sd</span><span class="p">,</span>
                             <span class="n">max_tries</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">retry_max_tries</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">mcmc_params</span> <span class="o">=</span> <span class="n">algo_res</span><span class="p">[</span><span class="s1">&#39;parameters&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prev_vals</span> <span class="o">=</span> <span class="n">algo_res</span><span class="p">[</span><span class="s1">&#39;prev_vals&#39;</span><span class="p">]</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">intercept_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">extra_params_sum_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_coefs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mcmc_params</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">param_summary</span><span class="p">,</span>
                                                                                 <span class="bp">self</span><span class="o">.</span><span class="n">extra_params</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">niter</span>
        
        <span class="c1"># get model summaries</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">over_dispersion</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dispersion_delta_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extra_params_sum_</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dispersion_estimation_</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">dispersion_delta_</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dispersion_delta_</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dispersion_estimation_</span> <span class="o">=</span> <span class="kc">None</span>
        
        <span class="n">ddu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_deviance_dispersion_update</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:],</span> <span class="n">y</span><span class="p">,</span>
                                               <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">deviance_</span> <span class="o">=</span> <span class="n">ddu</span><span class="p">[</span><span class="s1">&#39;deviance_&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">null_deviance_</span> <span class="o">=</span> <span class="n">ddu</span><span class="p">[</span><span class="s1">&#39;null_deviance_&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pearson_residuals_</span> <span class="o">=</span> <span class="n">ddu</span><span class="p">[</span><span class="s1">&#39;pearson_residuals_&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pearson_chi2_</span> <span class="o">=</span> <span class="n">ddu</span><span class="p">[</span><span class="s1">&#39;pearson_chi2_&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_d2_</span> <span class="o">=</span> <span class="n">ddu</span><span class="p">[</span><span class="s1">&#39;model_d2_&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df_model_</span> <span class="o">=</span> <span class="n">ddu</span><span class="p">[</span><span class="s1">&#39;df_model_&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df_residuals_</span> <span class="o">=</span> <span class="n">ddu</span><span class="p">[</span><span class="s1">&#39;df_residuals_&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df_total_</span> <span class="o">=</span> <span class="n">ddu</span><span class="p">[</span><span class="s1">&#39;df_total_&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dispersion_scale_</span> <span class="o">=</span> <span class="n">ddu</span><span class="p">[</span><span class="s1">&#39;dispersion_scale_&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dispersion_scale_sqrt_</span> <span class="o">=</span> <span class="n">ddu</span><span class="p">[</span><span class="s1">&#39;dispersion_scale_sqrt_&#39;</span><span class="p">]</span>
        
        <span class="k">return</span> <span class="bp">self</span></div>
    
<div class="viewcode-block" id="BayesPoissonRegressor.predict"><a class="viewcode-back" href="../../generated/tsdst.estimators.BayesPoissonRegressor.predict.html#tsdst.estimators.BayesPoissonRegressor.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;coef_&#39;</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;csr&#39;</span><span class="p">,</span> <span class="s1">&#39;csc&#39;</span><span class="p">,</span> <span class="s1">&#39;coo&#39;</span><span class="p">],</span>
                        <span class="n">dtype</span><span class="o">=</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">],</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">allow_nd</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">mu</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">intercept_</span>
        <span class="c1">#return np.exp(mu)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">dispersion_delta_</span><span class="p">)</span></div>
    
<div class="viewcode-block" id="BayesPoissonRegressor.score"><a class="viewcode-back" href="../../generated/tsdst.estimators.BayesPoissonRegressor.score.html#tsdst.estimators.BayesPoissonRegressor.score">[docs]</a>    <span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scorer</span> <span class="o">==</span> <span class="s1">&#39;D2&#39;</span><span class="p">:</span>
            <span class="n">ddu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_deviance_dispersion_update</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span>
                                                   <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
            <span class="n">score</span> <span class="o">=</span> <span class="n">ddu</span><span class="p">[</span><span class="s1">&#39;model_d2_&#39;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scorer</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">score</span></div></div>

    
<div class="viewcode-block" id="BayesWeibullRegressor"><a class="viewcode-back" href="../../generated/tsdst.estimators.BayesWeibullRegressor.html#tsdst.estimators.BayesWeibullRegressor">[docs]</a><span class="k">class</span> <span class="nc">BayesWeibullRegressor</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">LinearClassifierMixin</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A Weibull Regressor that uses MCMC to evaluate the parameters.</span>
<span class="sd">    This objects inherits from sklearn\&#39;s BaseEstimator and</span>
<span class="sd">    LinearClassifierMixin.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="BayesWeibullRegressor.__init__"><a class="viewcode-back" href="../../generated/tsdst.estimators.BayesWeibullRegressor.__init__.html#tsdst.estimators.BayesWeibullRegressor.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">niter</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">algo</span><span class="o">=</span><span class="s1">&#39;rosenthal&#39;</span><span class="p">,</span>
                 <span class="n">algo_options</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">retry_sd</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span> <span class="n">retry_max_tries</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                 <span class="n">initialize_weights</span><span class="o">=</span><span class="s1">&#39;sklearn&#39;</span><span class="p">,</span> <span class="n">param_summary</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span>
                 <span class="n">has_constant</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">over_dispersion</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The constructor for the BayesWeibullClassifier</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        C : float, optional</span>
<span class="sd">            The value for the inverse L1 penalty, or, the inverse</span>
<span class="sd">            regularization strength. If None, the MCMC process</span>
<span class="sd">            looks for the optimal penalty. The default is None.</span>
<span class="sd">            </span>
<span class="sd">            This value is gets converted into the scale parameter for a laplace</span>
<span class="sd">            distribution (scale = 2*C).</span>
<span class="sd">        start : numpy array (float), optional</span>
<span class="sd">            The starting values for the MCMC. If None, the MLE estimate is used</span>
<span class="sd">            (solved with sklearn). The default is None.</span>
<span class="sd">        niter : int, optional</span>
<span class="sd">            The number of MCMC samples to draw. The default is 10000.</span>
<span class="sd">        algo : str, optional</span>
<span class="sd">            The MCMC (Metropolis) algorithm to use. The default is &#39;rosenthal&#39;, which is </span>
<span class="sd">            a method that tunes the covariance matrix after each iteration.</span>
<span class="sd">            Other options include &#39;rwm&#39;, which is a simple random metropolis</span>
<span class="sd">            walk with a fixed covariance matrix, and &#39;lap&#39; which is another </span>
<span class="sd">            adaptive method that tunes the covariance matrix every K</span>
<span class="sd">            iterations.</span>
<span class="sd">        algo_options : dict, optional</span>
<span class="sd">            The options to be passed to the MCMC algorithm. Include as a</span>
<span class="sd">            dictionary. The default is None.</span>
<span class="sd">        retry_sd : float, optional</span>
<span class="sd">            The MCMC alorithms use a Cholesky decomposition on the covariance</span>
<span class="sd">            matrix. In case the decomposition fails, the algorithms will </span>
<span class="sd">            attempt to jitter the covaraince matrix to help it be positive </span>
<span class="sd">            definite. This value determines the strength of the jittering and</span>
<span class="sd">            is drawn directly from a normal distribution with zero mean and</span>
<span class="sd">            retry_sd standard deviation. The default is 0.02.</span>
<span class="sd">        retry_max_tries : int, optional</span>
<span class="sd">            Number of attempts to correct the cholesky decomposition if it</span>
<span class="sd">            fails. The default is 100.</span>
<span class="sd">        initialize_weights : str, optional</span>
<span class="sd">            Determines the method of initializing the starting model parameter</span>
<span class="sd">            values (if start is None). Options are &#39;sklearn&#39;, &#39;ones&#39;, &#39;random&#39;,</span>
<span class="sd">            or &#39;zeros&#39;. The default is &#39;sklearn&#39;.</span>
<span class="sd">        param_summary : str, optional</span>
<span class="sd">            The method used in making the final parameter summaries. Options </span>
<span class="sd">            are &#39;mean&#39;, &#39;median&#39;, &#39;mode_kde&#39;, &#39;mode_histogram&#39;, or</span>
<span class="sd">            &#39;final_sample&#39;. The default is &#39;mean&#39;.</span>
<span class="sd">        has_constant : bool, optional</span>
<span class="sd">            Whether or not the data provided already has a column of ones</span>
<span class="sd">            as the first column in the dataset for the intercept of the model.</span>
<span class="sd">            If not, one is created. The default is False.</span>
<span class="sd">        verbose : bool, optional</span>
<span class="sd">            If True, a progress bar, along with timestamps, is provided.</span>
<span class="sd">            The default is True.</span>
<span class="sd">        over_dispersion : bool, optional</span>
<span class="sd">            ---CURRENTLY NOT IMPLEMENTED---</span>
<span class="sd">            Whether or not to account for overdispersion in the model.</span>
<span class="sd">            The default is False.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        None.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">C</span> <span class="o">=</span> <span class="n">C</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">start</span> <span class="o">=</span> <span class="n">start</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">niter</span> <span class="o">=</span> <span class="n">niter</span>
        <span class="k">if</span> <span class="n">algo</span> <span class="o">==</span> <span class="s1">&#39;rosenthal&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">algo</span> <span class="o">=</span> <span class="n">adaptive_mcmc</span>
        <span class="k">elif</span> <span class="n">algo</span> <span class="o">==</span> <span class="s1">&#39;lap&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">algo</span> <span class="o">=</span> <span class="n">rwm_with_lap</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">algo</span> <span class="o">=</span> <span class="n">rwm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">algo_options</span> <span class="o">=</span> <span class="n">algo_options</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">param_summary</span> <span class="o">=</span> <span class="n">param_summary</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initialize_weights</span> <span class="o">=</span> <span class="n">initialize_weights</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">has_constant</span> <span class="o">=</span> <span class="n">has_constant</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">retry_sd</span> <span class="o">=</span> <span class="n">retry_sd</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">retry_max_tries</span> <span class="o">=</span> <span class="n">retry_max_tries</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lpost</span> <span class="o">=</span> <span class="n">weibull_regression_post</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">extra_params</span> <span class="o">=</span> <span class="mi">0</span></div>
            
    <span class="k">def</span> <span class="nf">_create_coefs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mcmc_params</span><span class="p">,</span> <span class="n">param_summary</span><span class="p">,</span> <span class="n">extra_params</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Creates Coefficients for MCMC model by aggregating the MCMC samples,</span>
<span class="sd">        using mean, median, mode, or last sampled value.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        mcmc_params : numpy array (float)</span>
<span class="sd">            MCMC chain, one column for each parameter.</span>
<span class="sd">        param_summary : str</span>
<span class="sd">            The method of aggregation (either mean, median, mode_kde,</span>
<span class="sd">            mode_histogram, or last_value.</span>
<span class="sd">        extra_params : int</span>
<span class="sd">            The number of extra params used in the MCMC process (for example,</span>
<span class="sd">        parameters for priors or overdispersion).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        coefs : numpy array (float)</span>
<span class="sd">            The coefficients of the model (aggregated from the MCMC chain).</span>
<span class="sd">        intercept : float</span>
<span class="sd">            The intercept of the model (aggregated from the MCMC chain).</span>
<span class="sd">        extra_parm : numpy array (float)</span>
<span class="sd">            Any extra parameters that were solved with the model (aggregated</span>
<span class="sd">            from the MCMC chain).</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">sum_parms</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">param_summary</span> <span class="o">==</span> <span class="s1">&#39;mean&#39;</span><span class="p">:</span>
            <span class="n">sum_parms</span> <span class="o">=</span> <span class="n">mcmc_params</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">param_summary</span> <span class="o">==</span> <span class="s1">&#39;median&#39;</span><span class="p">:</span>
            <span class="n">sum_parms</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">mcmc_params</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">param_summary</span> <span class="o">==</span> <span class="s1">&#39;mode_histogram&#39;</span><span class="p">:</span>
            <span class="n">sum_parms</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">mode_histogram</span><span class="p">(</span><span class="n">mcmc_params</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">mcmc_params</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])])</span>
        <span class="k">elif</span> <span class="n">param_summary</span> <span class="o">==</span> <span class="s1">&#39;mode_kde&#39;</span><span class="p">:</span>
            <span class="n">sum_parms</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">mode_kde</span><span class="p">(</span><span class="n">mcmc_params</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">mcmc_params</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">sum_parms</span> <span class="o">=</span> <span class="n">mcmc_params</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
        
        <span class="k">if</span> <span class="n">extra_params</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">extra_parm</span> <span class="o">=</span> <span class="n">sum_parms</span><span class="p">[</span><span class="o">-</span><span class="n">extra_params</span><span class="p">:]</span>
            <span class="n">coefs</span> <span class="o">=</span> <span class="n">sum_parms</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="n">extra_params</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">extra_parm</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">coefs</span> <span class="o">=</span> <span class="n">sum_parms</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">)</span>
        <span class="n">intercept</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">sum_parms</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        
        <span class="k">return</span> <span class="n">coefs</span><span class="p">,</span> <span class="n">intercept</span><span class="p">,</span> <span class="n">extra_parm</span>
    
    <span class="k">def</span> <span class="nf">_deviance_dispersion_update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">_check_sample_weight</span><span class="p">(</span><span class="n">sample_weight</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">y_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>
        <span class="n">deviance_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">weights</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">xlogy</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y</span><span class="o">/</span><span class="n">y_pred</span><span class="p">)</span> <span class="o">-</span> <span class="n">y</span> <span class="o">+</span> <span class="n">y_pred</span><span class="p">)))</span>
        <span class="n">null_deviance_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">weights</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">xlogy</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y</span><span class="o">/</span><span class="n">y_mean</span><span class="p">)</span> <span class="o">-</span> <span class="n">y</span> <span class="o">+</span> <span class="n">y_mean</span><span class="p">)))</span>
        <span class="c1"># pearson residual:  (raw residual)/(variance function)</span>
        <span class="c1"># TODO: put correct weibull variance here</span>
        <span class="n">pearson_residuals_</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">)</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
        <span class="n">pearson_chi2_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">pearson_residuals_</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">model_d2_</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">deviance_</span><span class="o">/</span><span class="n">null_deviance_</span>
        <span class="c1"># degrees of freedom of the model (all params (including intercept) minus 1)</span>
        <span class="n">df_model_</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="c1"># degrees of freedom of residuals ((n_obs - 1) - (nparms - 1)), or</span>
        <span class="n">df_residuals_</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="c1"># total degrees of freedom</span>
        <span class="n">df_total_</span> <span class="o">=</span> <span class="n">df_residuals_</span> <span class="o">+</span> <span class="n">df_model_</span>
        <span class="c1"># method of moments estimator for dispersion scale</span>
        <span class="n">dispersion_scale_</span> <span class="o">=</span> <span class="n">pearson_chi2_</span><span class="o">/</span><span class="n">df_residuals_</span>
        <span class="n">dispersion_scale_sqrt_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">dispersion_scale_</span><span class="p">)</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;deviance_&#39;</span><span class="p">:</span> <span class="n">deviance_</span><span class="p">,</span>
                   <span class="s1">&#39;null_deviance_&#39;</span><span class="p">:</span> <span class="n">null_deviance_</span><span class="p">,</span>
                   <span class="s1">&#39;pearson_residuals_&#39;</span><span class="p">:</span> <span class="n">pearson_residuals_</span><span class="p">,</span>
                   <span class="s1">&#39;pearson_chi2_&#39;</span><span class="p">:</span> <span class="n">pearson_chi2_</span><span class="p">,</span>
                   <span class="s1">&#39;model_d2_&#39;</span><span class="p">:</span> <span class="n">model_d2_</span><span class="p">,</span>
                   <span class="s1">&#39;df_model_&#39;</span><span class="p">:</span> <span class="n">df_model_</span><span class="p">,</span>
                   <span class="s1">&#39;df_residuals_&#39;</span><span class="p">:</span> <span class="n">df_residuals_</span><span class="p">,</span>
                   <span class="s1">&#39;df_total_&#39;</span><span class="p">:</span> <span class="n">df_total_</span><span class="p">,</span>
                   <span class="s1">&#39;dispersion_scale_&#39;</span><span class="p">:</span> <span class="n">dispersion_scale_</span><span class="p">,</span>
                   <span class="s1">&#39;dispersion_scale_sqrt_&#39;</span><span class="p">:</span> <span class="n">dispersion_scale_sqrt_</span><span class="p">}</span>
        <span class="k">return</span> <span class="n">results</span>
        
<div class="viewcode-block" id="BayesWeibullRegressor.adjust_params_"><a class="viewcode-back" href="../../generated/tsdst.estimators.BayesWeibullRegressor.adjust_params_.html#tsdst.estimators.BayesWeibullRegressor.adjust_params_">[docs]</a>    <span class="k">def</span> <span class="nf">adjust_params_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_param_summary</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;This method is intended to update the aggregated parameters with a new</span>
<span class="sd">        summary as defined in new_param_summary. For example, if someone wanted</span>
<span class="sd">        to switch from `coef_` representing the mean to `coef_` representing</span>
<span class="sd">        the median, they could use this function to do so.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        new_param_summary : str</span>
<span class="sd">            The method of aggregating the MCMC chain parameters (either mean,</span>
<span class="sd">            median, mode_kde, mode_histogram, or last_value).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self</span>
<span class="sd">            Updates the `coef_`, `intercept_`, and `extra_params_sum_` attributes.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">intercept_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">extra_params_sum_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_coefs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mcmc_params</span><span class="p">,</span> <span class="n">new_param_summary</span><span class="p">,</span>
                                                                                 <span class="bp">self</span><span class="o">.</span><span class="n">extra_params</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>
    
<div class="viewcode-block" id="BayesWeibullRegressor.fit"><a class="viewcode-back" href="../../generated/tsdst.estimators.BayesWeibullRegressor.fit.html#tsdst.estimators.BayesWeibullRegressor.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Fit the model</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : numpy array</span>
<span class="sd">            The feature (or design) matrix.</span>
<span class="sd">        y : numpy array</span>
<span class="sd">            The response variable.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self</span>
<span class="sd">            Updates internal attributes, such as `coef_` and `intercept_`.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">t0</span> <span class="o">=</span> <span class="n">dt</span><span class="p">()</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">force_all_finite</span><span class="o">=</span><span class="s1">&#39;allow-nan&#39;</span><span class="p">,</span> <span class="n">estimator</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_constant</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">add_constant</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">prepend</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>       
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">start</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">pass</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="n">print_time</span><span class="p">(</span><span class="s2">&quot;Initializing Coefficients...&quot;</span><span class="p">,</span> <span class="n">t0</span><span class="p">,</span> <span class="n">dt</span><span class="p">(),</span> <span class="n">backsn</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">initialize_weights</span> <span class="o">==</span> <span class="s1">&#39;sklearn&#39;</span><span class="p">:</span>
                <span class="n">C</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">C</span>
                <span class="k">if</span> <span class="n">C</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">C</span> <span class="o">=</span> <span class="mi">1</span>
                <span class="c1"># TODO: update with Weibull Regression starting values</span>
                <span class="c1">### If using sklearn version 0.23.2, can use this line instead</span>
                <span class="c1">#mod = glm_pois(alpha=1/C, fit_intercept=False, max_iter=1000).fit(X, y)</span>
                <span class="c1">#self.start = mod.coef_.reshape(-1, )</span>
                <span class="c1">### else, use statsmodels</span>
                <span class="n">mod</span> <span class="o">=</span> <span class="n">glm_pois</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="n">Poisson</span><span class="p">())</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">start</span> <span class="o">=</span> <span class="n">mod</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">extra_params</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">start</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">start</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">extra_params</span><span class="p">)))</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">initialize_weights</span> <span class="o">==</span> <span class="s1">&#39;ones&#39;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">start</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">extra_params</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">initialize_weights</span> <span class="o">==</span> <span class="s1">&#39;random&#39;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">start</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">extra_params</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">start</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">extra_params</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="n">print_time</span><span class="p">(</span><span class="s2">&quot;Beginning MCMC...&quot;</span><span class="p">,</span> <span class="n">t0</span><span class="p">,</span> <span class="n">dt</span><span class="p">(),</span> <span class="n">backsn</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        
        <span class="n">postArgs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">X</span><span class="p">,</span>
            <span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">y</span><span class="p">,</span>
            <span class="s1">&#39;l_scale&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">C</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">C</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">2</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">C</span>
        <span class="p">}</span>
        
        <span class="n">algo_res</span> <span class="o">=</span> <span class="n">applyMCMC</span><span class="p">(</span><span class="n">st</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">start</span><span class="p">,</span> <span class="n">ni</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">niter</span><span class="p">,</span> <span class="n">lp</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lpost</span><span class="p">,</span>
                             <span class="n">algo</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">algo</span><span class="p">,</span> <span class="n">postArgs</span><span class="o">=</span><span class="n">postArgs</span><span class="p">,</span>
                             <span class="n">algoOpts</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">algo_options</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">retry_sd</span><span class="p">,</span>
                             <span class="n">max_tries</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">retry_max_tries</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">mcmc_params</span> <span class="o">=</span> <span class="n">algo_res</span><span class="p">[</span><span class="s1">&#39;parameters&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prev_vals</span> <span class="o">=</span> <span class="n">algo_res</span><span class="p">[</span><span class="s1">&#39;prev_vals&#39;</span><span class="p">]</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">intercept_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">extra_params_sum_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_coefs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mcmc_params</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">param_summary</span><span class="p">,</span>
                                                                                 <span class="bp">self</span><span class="o">.</span><span class="n">extra_params</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">niter</span>
        
        <span class="c1">#get model summaries</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">_check_sample_weight</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:])</span>
        <span class="n">y_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>
        <span class="n">dev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">weights</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">xlogy</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y</span><span class="o">/</span><span class="n">y_pred</span><span class="p">)</span> <span class="o">-</span> <span class="n">y</span> <span class="o">+</span> <span class="n">y_pred</span><span class="p">)))</span>
        <span class="n">dev_null</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">weights</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">xlogy</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y</span><span class="o">/</span><span class="n">y_mean</span><span class="p">)</span> <span class="o">-</span> <span class="n">y</span> <span class="o">+</span> <span class="n">y_mean</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">deviance_</span> <span class="o">=</span> <span class="n">dev</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">null_deviance_</span> <span class="o">=</span> <span class="n">dev_null</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pearson_residuals_</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">)</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pearson_chi2_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pearson_residuals_</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_d2_</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">dev</span><span class="o">/</span><span class="n">dev_null</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df_model_</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df_residuals_</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dispersion_scale_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pearson_chi2_</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">df_residuals_</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dispersion_scale_sqrt_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dispersion_scale_</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="bp">self</span></div>
    
<div class="viewcode-block" id="BayesWeibullRegressor.predict"><a class="viewcode-back" href="../../generated/tsdst.estimators.BayesWeibullRegressor.predict.html#tsdst.estimators.BayesWeibullRegressor.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;coef_&#39;</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;csr&#39;</span><span class="p">,</span> <span class="s1">&#39;csc&#39;</span><span class="p">,</span> <span class="s1">&#39;coo&#39;</span><span class="p">],</span>
                        <span class="n">dtype</span><span class="o">=</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">],</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">allow_nd</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">mu</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">intercept_</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span></div>
    
<div class="viewcode-block" id="BayesWeibullRegressor.score"><a class="viewcode-back" href="../../generated/tsdst.estimators.BayesWeibullRegressor.score.html#tsdst.estimators.BayesWeibullRegressor.score">[docs]</a>    <span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">scorer</span><span class="o">=</span><span class="s1">&#39;D2&#39;</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">scorer</span> <span class="o">==</span> <span class="s1">&#39;D2&#39;</span><span class="p">:</span>
            <span class="n">ddu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_deviance_dispersion_update</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:],</span> <span class="n">y</span><span class="p">,</span>
                                                   <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
            <span class="n">score</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">ddu</span><span class="p">[</span><span class="s1">&#39;deviance_&#39;</span><span class="p">]</span><span class="o">/</span><span class="n">ddu</span><span class="p">[</span><span class="s1">&#39;null_deviance_&#39;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">score</span> <span class="o">=</span> <span class="n">scorer</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">score</span></div></div>
    

<span class="k">class</span> <span class="nc">LogReg</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">LinearClassifierMixin</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A class for performing Logistic Regression using scipy.optimize.minimize.</span>
<span class="sd">    This is not meant to replace skleaarn&#39;s implementation, and in fact, it</span>
<span class="sd">    is mainly built on sklearn. This was mainly a test for the author to get a</span>
<span class="sd">    better understanding of both the internals of sklearn and</span>
<span class="sd">    Logistic Regression</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x0</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">lamb</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">l_norm</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">jac</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">hess</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">hessp</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">constraints</span><span class="o">=</span><span class="p">(),</span> <span class="n">tol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">callback</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">has_constant</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">optimize_args</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;fun&#39;</span><span class="p">:</span> <span class="n">likelihood_bernoulli</span><span class="p">,</span>
                              <span class="s1">&#39;x0&#39;</span><span class="p">:</span> <span class="n">x0</span><span class="p">,</span>
                              <span class="s1">&#39;method&#39;</span><span class="p">:</span> <span class="n">method</span><span class="p">,</span>
                              <span class="s1">&#39;jac&#39;</span><span class="p">:</span> <span class="n">jac</span><span class="p">,</span>
                              <span class="s1">&#39;hess&#39;</span><span class="p">:</span> <span class="n">hess</span><span class="p">,</span>
                              <span class="s1">&#39;hessp&#39;</span><span class="p">:</span> <span class="n">hessp</span><span class="p">,</span>
                              <span class="s1">&#39;bounds&#39;</span><span class="p">:</span> <span class="n">bounds</span><span class="p">,</span>
                              <span class="s1">&#39;constraints&#39;</span><span class="p">:</span> <span class="n">constraints</span><span class="p">,</span>
                              <span class="s1">&#39;tol&#39;</span><span class="p">:</span> <span class="n">tol</span><span class="p">,</span>
                              <span class="s1">&#39;callback&#39;</span><span class="p">:</span> <span class="n">callback</span><span class="p">,</span>
                              <span class="s1">&#39;options&#39;</span><span class="p">:</span> <span class="n">options</span>
                             <span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lamb</span> <span class="o">=</span> <span class="n">lamb</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l_norm</span> <span class="o">=</span> <span class="n">l_norm</span>
        
        
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit the model</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : numpy array</span>
<span class="sd">            The feature (or design) matrix.</span>
<span class="sd">        y : numpy array</span>
<span class="sd">            The response variable.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self</span>
<span class="sd">            Updates internal attributes, such as coef_ and intercept_.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_constant</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">add_constant</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">prepend</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimize_args</span><span class="p">[</span><span class="s1">&#39;x0&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimize_args</span><span class="p">[</span><span class="s1">&#39;x0&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="c1">#self.optimize_args[&#39;x0&#39;] = np.random.normal(size=X.shape[1])</span>
        
        <span class="n">args</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">lamb</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">l_norm</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">optimize_args</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;args&#39;</span><span class="p">:</span> <span class="n">args</span><span class="p">})</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optim_results</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">optimize_args</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">intercept_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optim_results</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optim_results</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optim_results</span><span class="o">.</span><span class="n">nit</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classes_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>
    
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="c1"># note: decision_function returns X.dot(Betas). This code, modified from sklearn,</span>
        <span class="c1"># computes the decision based on the sign of the log odds ratio (X.dot(betas) == log(p/(1-p))).</span>
        <span class="c1"># When p &lt;= 0.5, decision is 0, when p &gt; 0.5, decision is 1 (threshold of 0.5 is the default for sklearn). </span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">scores</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="p">(</span><span class="n">scores</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># returning the value in this way allows for someone to define their own classes,</span>
        <span class="c1"># for example, -1, 1 instead of 0, 1</span>
        <span class="c1"># Note: this is used in sklearn, but this code is not be robust enough for that,</span>
        <span class="c1"># so you need to define your classes as 0, 1</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">classes_</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
    
    <span class="k">def</span> <span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generate predicted probability.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : numpy array</span>
<span class="sd">            Feature (or design) matrix.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        numpy array (float)</span>
<span class="sd">            The predicted probabilities.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1">#check_is_fitted(self)</span>
        
        <span class="n">decision</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">decision_2d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="o">-</span><span class="n">decision</span><span class="p">,</span> <span class="n">decision</span><span class="p">]</span>
        
        <span class="k">return</span> <span class="n">softmax</span><span class="p">(</span><span class="n">decision_2d</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">predict_log_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1">#TODO: Test default scoring</span>
        <span class="n">scoring</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scoring</span> <span class="ow">or</span> <span class="s1">&#39;accuracy&#39;</span>
        <span class="n">scoring</span> <span class="o">=</span> <span class="n">get_scorer</span><span class="p">(</span><span class="n">scoring</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">scoring</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
</pre></div>

    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2020 - present, Tom Werner.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.1.2.<br/>
    </p>
  </div>
</footer>
  </body>
</html>